{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This Notebook is to Experiment LangGraph Agents\n",
    "\n",
    "The Sequential Tasks are:\n",
    "- Collect Model information from MLFlow run\n",
    "- Collect the notebook information\n",
    "- Write a ML document draft\n",
    "- Review the draft and create a final version"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T23:00:27.814326Z",
     "start_time": "2025-04-19T23:00:27.785157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mlflow\n",
    "from databricks.connect import DatabricksSession\n",
    "from dotenv import load_dotenv\n",
    "from jedi.inference.gradual.typing import TypedDict\n",
    "\n",
    "spark = DatabricksSession.builder.getOrCreate()\n",
    "load_dotenv('../.env')\n",
    "\n",
    "DATABRICKS_HOST = os.getenv('host')\n",
    "DATABRICKS_TOKEN = os.getenv('token')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "print(f\"host: {DATABRICKS_HOST}\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host: adb-984752964297111.11.azuredatabricks.net\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check the ML Model"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:39:52.678800Z",
     "start_time": "2025-04-19T22:39:52.659579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from unitycatalog.ai.core.base import set_uc_function_client\n",
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient\n",
    "\n",
    "client = DatabricksFunctionClient()\n",
    "set_uc_function_client(client)\n",
    "\n",
    "CATALOG = 'qyu'\n",
    "SCHEMA = 'dbdemos_fs_travel'\n",
    "model = 'dbdemos_fs_travel_model'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create LangGraph Agents"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:39:58.740778Z",
     "start_time": "2025-04-19T22:39:57.303887Z"
    }
   },
   "source": [
    "from typing import Any, Generator, Optional, Sequence, Union, TypedDict, Dict, List\n",
    "\n",
    "import mlflow\n",
    "from databricks_langchain import ChatDatabricks, VectorSearchRetrieverTool\n",
    "from databricks_langchain.uc_ai import (\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "\n",
    "local = True\n",
    "if local:\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_registry_uri(\"http://localhost:5000\")\n",
    "\n",
    "mlflow.set_experiment(\"langgraph_test\")\n",
    "mlflow.langchain.autolog()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:40:00.294107Z",
     "start_time": "2025-04-19T22:40:00.281979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = DatabricksFunctionClient()\n",
    "set_uc_function_client(client)\n",
    "\n",
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "LLM = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "# Prompts\n",
    "WRITTER_PROMPT = \"\"\"\n",
    "      You are a technical document writer with experience in creating detailed technical document\n",
    "       for machine learning models. You are skilled in organizing complex information and\n",
    "      presenting it in a clear and concise manner. You use content from machine learning\n",
    "      notebooks, model experiment run information, model explainability plots, model artifacts\n",
    "      files to craft the detailed machine learning technical document. Always remember:\n",
    "      1. Make sure section titles and subtitles are properly named\n",
    "      2. Have a hign-level description for each section before the technical details\n",
    "      3. Use markdown format for writting the document\n",
    "\"\"\"\n",
    "\n",
    "REVIEWER_PROMPT = \"\"\"\n",
    "      You are a technical document editor with experience in editing machine learning technical\n",
    "      documents. You are skilled in reviewing and refining content to ensure accuracy, clarity,\n",
    "      and consistency. You write the edited technical document and produce a final version of the document.\n",
    "      always remember:\n",
    "      1. check for grammar, style and accuracy\n",
    "      2. Ensure that the document is well-structured and easy to follow\n",
    "      3. Use markdown format for writing the document\n",
    "\"\"\"\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b3/rdsklr3d0s1f_fzq3pg5try40000gp/T/ipykernel_38736/3034012170.py:8: DeprecationWarning: Currently, temperature defaults to 0.0 if not specified. In the next release, temperature will need to be explicitly set. Please update your code to specify a temperature value. Note: If you are using an o1 or o3 model, you need to set temperature=None.\n",
      "  LLM = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T23:11:17.956974Z",
     "start_time": "2025-04-19T23:11:17.540768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.model_artifacts_organizer import ModelArtifactOrganizer\n",
    "\n",
    "model_test = ModelArtifactOrganizer(catalog=CATALOG, schema=SCHEMA, model=model)\n",
    "model_test.collect_mlflow_artifacts()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model_artifact_organizer:Creating folder: /Volumes/qyu/dbdemos_fs_travel/ml_documents/dbdemos_fs_travel_model\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/Volumes/qyu'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_artifacts_organizer\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ModelArtifactOrganizer\n\u001B[1;32m      3\u001B[0m model_test \u001B[38;5;241m=\u001B[39m ModelArtifactOrganizer(catalog\u001B[38;5;241m=\u001B[39mCATALOG, schema\u001B[38;5;241m=\u001B[39mSCHEMA, model\u001B[38;5;241m=\u001B[39mmodel)\n\u001B[0;32m----> 4\u001B[0m \u001B[43mmodel_test\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect_mlflow_artifacts\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/src/model_artifacts_organizer.py:29\u001B[0m, in \u001B[0;36mModelArtifactOrganizer.collect_mlflow_artifacts\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     25\u001B[0m model_version \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mget_model_version_by_alias(\n\u001B[1;32m     26\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_full_name, alias\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mproduction\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     27\u001B[0m )\n\u001B[1;32m     28\u001B[0m run_id \u001B[38;5;241m=\u001B[39m model_version\u001B[38;5;241m.\u001B[39mrun_id\n\u001B[0;32m---> 29\u001B[0m destination_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_uc_artifact_folder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvolume_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvolume_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfolder_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m mlflow\u001B[38;5;241m.\u001B[39martifacts\u001B[38;5;241m.\u001B[39mdownload_artifacts(\n\u001B[1;32m     33\u001B[0m     artifact_uri\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mruns:/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrun_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m, dst_path\u001B[38;5;241m=\u001B[39mdestination_path\n\u001B[1;32m     34\u001B[0m )\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m destination_path\n",
      "File \u001B[0;32m~/workspace/genai_dev/src/model_artifacts_organizer.py:45\u001B[0m, in \u001B[0;36mModelArtifactOrganizer.create_uc_artifact_folder\u001B[0;34m(volume_path, folder_name)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(folder_path):\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 45\u001B[0m         \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfolder_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m         logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPASS: Folder `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfolder_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` created\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m PermissionDenied:\n",
      "File \u001B[0;32m~/.local/share/uv/python/cpython-3.10.12-macos-aarch64-none/lib/python3.10/os.py:215\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m head \u001B[38;5;129;01mand\u001B[39;00m tail \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39mexists(head):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhead\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexist_ok\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileExistsError\u001B[39;00m:\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;66;03m# Defeats race condition when another thread created the path\u001B[39;00m\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/uv/python/cpython-3.10.12-macos-aarch64-none/lib/python3.10/os.py:215\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m head \u001B[38;5;129;01mand\u001B[39;00m tail \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39mexists(head):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhead\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexist_ok\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileExistsError\u001B[39;00m:\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;66;03m# Defeats race condition when another thread created the path\u001B[39;00m\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/uv/python/cpython-3.10.12-macos-aarch64-none/lib/python3.10/os.py:215\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m head \u001B[38;5;129;01mand\u001B[39;00m tail \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39mexists(head):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhead\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexist_ok\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileExistsError\u001B[39;00m:\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;66;03m# Defeats race condition when another thread created the path\u001B[39;00m\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/uv/python/cpython-3.10.12-macos-aarch64-none/lib/python3.10/os.py:225\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    223\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 225\u001B[0m     \u001B[43mmkdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001B[39;00m\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m exist_ok \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39misdir(name):\n",
      "\u001B[0;31mPermissionError\u001B[0m: [Errno 13] Permission denied: '/Volumes/qyu'"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:40:01.825660Z",
     "start_time": "2025-04-19T22:40:01.510637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.model_artifacts_organizer import ModelArtifactOrganizer\n",
    "from src.file_management_utils import recursive_file_loader\n",
    "\n",
    "\n",
    "def collect_ml_document_content(state: ChatAgentState) -> dict:\n",
    "    \"\"\"Process the content organization.\"\"\"\n",
    "    model_artifacts_organizer = ModelArtifactOrganizer(catalog=state['custom_inputs']['catalog'],\n",
    "                                                       schema=state['custom_inputs']['schema'],\n",
    "                                                       model=state['custom_inputs']['model'])\n",
    "    # Collect ML model assets\n",
    "    artifact_volume_path = model_artifacts_organizer.collect_mlflow_artifacts()\n",
    "\n",
    "    # Create model attributes table, notebook, and image markdown\n",
    "    model_artifacts_organizer.create_model_attributes_md()\n",
    "    model_artifacts_organizer.notebook_to_md()\n",
    "    model_artifacts_organizer.image_file_to_md()\n",
    "\n",
    "    # Collect content source files\n",
    "    doc_contents = recursive_file_loader(artifact_volume_path)\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a MLops experts\"},\n",
    "                {\"role\": \"user\", \"content\": \"Collected ML model assets, generated model \"\n",
    "                                            \"attributes table, notebook, and image markdown.\"}]\n",
    "\n",
    "    # Create a summary of all files\n",
    "    files_content = \"\\n\\n\".join([\n",
    "        f\"File: {doc.metadata['relative_path']}\\nType: {doc.metadata['file_type']}\\nContent: {doc.page_content}\"\n",
    "        for doc in doc_contents\n",
    "    ])\n",
    "    custom_outputs = state.get('custom_outputs', {}).copy()\n",
    "    custom_outputs['source_contents'] = files_content\n",
    "    state[\"custom_outputs\"]['source_contents'] = files_content\n",
    "    messages.append({\"role\": \"system\", \"content\": files_content})\n",
    "\n",
    "    return {\"messages\": messages, \"custom_outputs\": custom_outputs}\n",
    "\n",
    "\n",
    "def write_doc_draft(state: ChatAgentState, config: RunnableConfig) -> dict:\n",
    "    \"\"\"write the ml document draft\"\"\"\n",
    "\n",
    "    files_content = state.get(\"custom_outputs\", {}).get(\"source_contents\", \"No content found\")\n",
    "    content_message = {\"role\": \"user\", \"content\": f\"Here is the content of the files: {files_content}\"}\n",
    "   # Generate the outline\n",
    "    preprocessor = RunnableLambda(\n",
    "            lambda state: [{\"role\": \"system\", \"content\": WRITTER_PROMPT}]\n",
    "                          + state[\"messages\"] + [content_message]\n",
    "    )\n",
    "\n",
    "    model_runnable = preprocessor | LLM\n",
    "    response = model_runnable.invoke(state, config)\n",
    "\n",
    "    custom_outputs = state.get('custom_outputs', {}).copy()\n",
    "    custom_outputs['document_draft'] = response.content\n",
    "    state[\"custom_outputs\"]['document_draft'] = response.content\n",
    "\n",
    "    return {\"messages\": [response.dict()], \"custom_outputs\": custom_outputs}\n",
    "\n",
    "def review_doc_draft(state: ChatAgentState, config: RunnableConfig) -> dict:\n",
    "    \"\"\"review the ml document draft and write the final version\"\"\"\n",
    "\n",
    "    doc_draft = state.get(\"custom_outputs\", {}).get(\"document_draft\", \"No draft available\")\n",
    "    draft_message = {\"role\": \"user\", \"content\": f\"Here is the draft of the ml document: \"\n",
    "                                                f\"{doc_draft}\"}\n",
    "    # Generate the outline\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: [{\"role\": \"system\", \"content\": REVIEWER_PROMPT}]\n",
    "                      + state[\"messages\"] + [draft_message]\n",
    "    )\n",
    "    model_runnable = preprocessor | LLM\n",
    "    response = model_runnable.invoke(state, config)\n",
    "\n",
    "    custom_outputs = state.get('custom_outputs', {}).copy()\n",
    "    custom_outputs['final_document'] = response.content\n",
    "    state[\"custom_outputs\"]['final_document'] = response.content\n",
    "\n",
    "    return {\"messages\": [response.dict()], \"custom_outputs\": custom_outputs}"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:40:03.985647Z",
     "start_time": "2025-04-19T22:40:03.979838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "workflow = StateGraph(ChatAgentState)\n",
    "\n",
    "# Create nodes\n",
    "workflow.add_node(\"collect_ml_document_content\", collect_ml_document_content)\n",
    "workflow.add_node(\"write_doc_draft\", RunnableLambda(write_doc_draft))\n",
    "workflow.add_node(\"review_doc_draft\", RunnableLambda(review_doc_draft))\n",
    "\n",
    "# Create edges\n",
    "workflow.set_entry_point(\"collect_ml_document_content\")\n",
    "workflow.add_edge(\"collect_ml_document_content\", \"write_doc_draft\")\n",
    "workflow.add_edge(\"write_doc_draft\", \"review_doc_draft\")\n",
    "\n",
    "auto_ml_doc_flow = workflow.compile()"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:40:05.180472Z",
     "start_time": "2025-04-19T22:40:04.976443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(auto_ml_doc_flow.get_graph().draw_mermaid_png()))"
   ],
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:40:08.870976Z",
     "start_time": "2025-04-19T22:40:08.865529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LangGraphChatAgent(ChatAgent):\n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "            self,\n",
    "            messages: list[ChatAgentMessage],\n",
    "            context: Optional[ChatContext] = None,\n",
    "            custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        if context:\n",
    "            request[\"context\"] = context\n",
    "\n",
    "        if custom_inputs:\n",
    "            request[\"custom_inputs\"] = custom_inputs\n",
    "\n",
    "        messages = []\n",
    "        custom_outputs = {}\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                messages.extend(\n",
    "                    ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "                )\n",
    "                if \"custom_outputs\" in node_data:\n",
    "                    custom_outputs.update(node_data[\"custom_outputs\"])\n",
    "\n",
    "        return ChatAgentResponse(messages=messages, custom_outputs=custom_outputs)\n",
    "\n",
    "    def predict_stream(\n",
    "            self,\n",
    "            messages: list[ChatAgentMessage],\n",
    "            context: Optional[ChatContext] = None,\n",
    "            custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        if context:\n",
    "            request[\"context\"] = context\n",
    "\n",
    "        if custom_inputs:\n",
    "            request[\"custom_inputs\"] = custom_inputs\n",
    "\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                yield from (\n",
    "                    ChatAgentChunk(**{\"delta\": msg}) for msg in node_data[\"messages\"]\n",
    "                )\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:40:10.853094Z",
     "start_time": "2025-04-19T22:40:10.705025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AGENT = LangGraphChatAgent(auto_ml_doc_flow)\n",
    "mlflow.models.set_model(AGENT)\n",
    "AGENT.predict(messages={\"messages\": [{\"role\": \"user\", \"content\": \"Create a comprehensive ML document\"}]},\n",
    "              custom_inputs={\"catalog\": CATALOG, \"schema\": SCHEMA, \"model\": model})"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'model_dump_compat'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m AGENT \u001B[38;5;241m=\u001B[39m LangGraphChatAgent(auto_ml_doc_flow)\n\u001B[1;32m      2\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mmodels\u001B[38;5;241m.\u001B[39mset_model(AGENT)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mAGENT\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCreate a comprehensive ML document\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m              \u001B[49m\u001B[43mcustom_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcatalog\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mCATALOG\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mschema\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mSCHEMA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/pyfunc/utils/data_validation.py:126\u001B[0m, in \u001B[0;36mwrap_non_list_predict_pydantic.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    121\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, pydantic_obj)\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    123\u001B[0m     \u001B[38;5;66;03m# Before logging, this is equivalent to the behavior from the raw predict method\u001B[39;00m\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;66;03m# After logging, signature enforcement happens in the _convert_input method\u001B[39;00m\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;66;03m# of the wrapper class\u001B[39;00m\n\u001B[0;32m--> 126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[8], line 11\u001B[0m, in \u001B[0;36mLangGraphChatAgent.predict\u001B[0;34m(self, messages, context, custom_inputs)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpredict\u001B[39m(\n\u001B[1;32m      6\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m      7\u001B[0m         messages: \u001B[38;5;28mlist\u001B[39m[ChatAgentMessage],\n\u001B[1;32m      8\u001B[0m         context: Optional[ChatContext] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m      9\u001B[0m         custom_inputs: Optional[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     10\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatAgentResponse:\n\u001B[0;32m---> 11\u001B[0m     request \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_messages_to_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m}\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m context:\n\u001B[1;32m     14\u001B[0m         request[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontext\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m context\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/pyfunc/model.py:669\u001B[0m, in \u001B[0;36mChatAgent._convert_messages_to_dict\u001B[0;34m(self, messages)\u001B[0m\n\u001B[1;32m    668\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_convert_messages_to_dict\u001B[39m(\u001B[38;5;28mself\u001B[39m, messages: \u001B[38;5;28mlist\u001B[39m[ChatAgentMessage]):\n\u001B[0;32m--> 669\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [m\u001B[38;5;241m.\u001B[39mmodel_dump_compat(exclude_none\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m messages]\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/pyfunc/model.py:669\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    668\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_convert_messages_to_dict\u001B[39m(\u001B[38;5;28mself\u001B[39m, messages: \u001B[38;5;28mlist\u001B[39m[ChatAgentMessage]):\n\u001B[0;32m--> 669\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_dump_compat\u001B[49m(exclude_none\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m messages]\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'str' object has no attribute 'model_dump_compat'"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:40:14.624745Z",
     "start_time": "2025-04-19T22:40:12.041403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"Create a comprehensive ML document\"}],\n",
    "              \"custom_inputs\": {\"catalog\": CATALOG, \"schema\": SCHEMA, \"model\": model}})"
   ],
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "RESOURCE_DOES_NOT_EXIST: Registered Model with name=qyu.dbdemos_fs_travel.dbdemos_fs_travel_model not found",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRestException\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mAGENT\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCreate a comprehensive ML document\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m              \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcustom_inputs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcatalog\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mCATALOG\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mschema\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mSCHEMA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m}\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/pyfunc/utils/data_validation.py:119\u001B[0m, in \u001B[0;36mwrap_non_list_predict_pydantic.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    117\u001B[0m     param_names \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39msignature(func)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mkeys() \u001B[38;5;241m-\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m    118\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m {k: \u001B[38;5;28mgetattr\u001B[39m(pydantic_obj, k) \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m param_names}\n\u001B[0;32m--> 119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, pydantic_obj)\n",
      "Cell \u001B[0;32mIn[8], line 21\u001B[0m, in \u001B[0;36mLangGraphChatAgent.predict\u001B[0;34m(self, messages, context, custom_inputs)\u001B[0m\n\u001B[1;32m     19\u001B[0m messages \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     20\u001B[0m custom_outputs \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m---> 21\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m event \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39magent\u001B[38;5;241m.\u001B[39mstream(request, stream_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mupdates\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m node_data \u001B[38;5;129;01min\u001B[39;00m event\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[1;32m     23\u001B[0m         messages\u001B[38;5;241m.\u001B[39mextend(\n\u001B[1;32m     24\u001B[0m             ChatAgentMessage(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmsg) \u001B[38;5;28;01mfor\u001B[39;00m msg \u001B[38;5;129;01min\u001B[39;00m node_data\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, [])\n\u001B[1;32m     25\u001B[0m         )\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2356\u001B[0m, in \u001B[0;36mPregel.stream\u001B[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001B[0m\n\u001B[1;32m   2350\u001B[0m     \u001B[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001B[39;00m\n\u001B[1;32m   2351\u001B[0m     \u001B[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001B[39;00m\n\u001B[1;32m   2352\u001B[0m     \u001B[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001B[39;00m\n\u001B[1;32m   2353\u001B[0m     \u001B[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001B[39;00m\n\u001B[1;32m   2354\u001B[0m     \u001B[38;5;66;03m# with channel updates applied only at the transition between steps.\u001B[39;00m\n\u001B[1;32m   2355\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m loop\u001B[38;5;241m.\u001B[39mtick(input_keys\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_channels):\n\u001B[0;32m-> 2356\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m runner\u001B[38;5;241m.\u001B[39mtick(\n\u001B[1;32m   2357\u001B[0m             loop\u001B[38;5;241m.\u001B[39mtasks\u001B[38;5;241m.\u001B[39mvalues(),\n\u001B[1;32m   2358\u001B[0m             timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_timeout,\n\u001B[1;32m   2359\u001B[0m             retry_policy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry_policy,\n\u001B[1;32m   2360\u001B[0m             get_waiter\u001B[38;5;241m=\u001B[39mget_waiter,\n\u001B[1;32m   2361\u001B[0m         ):\n\u001B[1;32m   2362\u001B[0m             \u001B[38;5;66;03m# emit output\u001B[39;00m\n\u001B[1;32m   2363\u001B[0m             \u001B[38;5;28;01myield from\u001B[39;00m output()\n\u001B[1;32m   2364\u001B[0m \u001B[38;5;66;03m# emit output\u001B[39;00m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/pregel/runner.py:158\u001B[0m, in \u001B[0;36mPregelRunner.tick\u001B[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001B[0m\n\u001B[1;32m    156\u001B[0m t \u001B[38;5;241m=\u001B[39m tasks[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 158\u001B[0m     \u001B[43mrun_with_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfigurable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m            \u001B[49m\u001B[43mCONFIG_KEY_CALL\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m                \u001B[49m\u001B[43m_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m                \u001B[49m\u001B[43mweakref\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m                \u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[43m                \u001B[49m\u001B[43mfutures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweakref\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfutures\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m                \u001B[49m\u001B[43mschedule_task\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mschedule_task\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m                \u001B[49m\u001B[43msubmit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m                \u001B[49m\u001B[43mreraise\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommit(t, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/pregel/retry.py:39\u001B[0m, in \u001B[0;36mrun_with_retry\u001B[0;34m(task, retry_policy, configurable)\u001B[0m\n\u001B[1;32m     37\u001B[0m     task\u001B[38;5;241m.\u001B[39mwrites\u001B[38;5;241m.\u001B[39mclear()\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;66;03m# run the task\u001B[39;00m\n\u001B[0;32m---> 39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ParentCommand \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     41\u001B[0m     ns: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/utils/runnable.py:622\u001B[0m, in \u001B[0;36mRunnableSeq.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    620\u001B[0m     \u001B[38;5;66;03m# run in context\u001B[39;00m\n\u001B[1;32m    621\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m set_config_context(config, run) \u001B[38;5;28;01mas\u001B[39;00m context:\n\u001B[0;32m--> 622\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    623\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    624\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:483\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    479\u001B[0m call_original \u001B[38;5;241m=\u001B[39m update_wrapper_extended(call_original, original)\n\u001B[1;32m    481\u001B[0m event_logger\u001B[38;5;241m.\u001B[39mlog_patch_function_start(args, kwargs)\n\u001B[0;32m--> 483\u001B[0m \u001B[43mpatch_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcall_original\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    485\u001B[0m session\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    486\u001B[0m event_logger\u001B[38;5;241m.\u001B[39mlog_patch_function_success(args, kwargs)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/langchain/_langchain_autolog.py:74\u001B[0m, in \u001B[0;36mpatched_inference\u001B[0;34m(func_name, original, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     72\u001B[0m         _log_optional_artifacts(config, run_id, result, \u001B[38;5;28mself\u001B[39m, func_name, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 74\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_invoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/langchain/_langchain_autolog.py:66\u001B[0m, in \u001B[0;36mpatched_inference.<locals>._invoke\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_invoke\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m disable_patching():\n\u001B[0;32m---> 66\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:474\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001B[0;34m(*og_args, **og_kwargs)\u001B[0m\n\u001B[1;32m    471\u001B[0m         original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n\u001B[1;32m    472\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n\u001B[0;32m--> 474\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall_original_fn_with_event_logging\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_original_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mog_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mog_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:425\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001B[0;34m(original_fn, og_args, og_kwargs)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    423\u001B[0m     event_logger\u001B[38;5;241m.\u001B[39mlog_original_function_start(og_args, og_kwargs)\n\u001B[0;32m--> 425\u001B[0m     original_fn_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mog_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mog_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    427\u001B[0m     event_logger\u001B[38;5;241m.\u001B[39mlog_original_function_success(og_args, og_kwargs)\n\u001B[1;32m    428\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_fn_result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:471\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001B[0;34m(*_og_args, **_og_kwargs)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001B[39;00m\n\u001B[1;32m    464\u001B[0m \u001B[38;5;66;03m# during original function execution, even if silent mode is enabled\u001B[39;00m\n\u001B[1;32m    465\u001B[0m \u001B[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001B[39;00m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001B[39;00m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m NonMlflowWarningsBehaviorForCurrentThread(\n\u001B[1;32m    468\u001B[0m     disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    469\u001B[0m     reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    470\u001B[0m ):\n\u001B[0;32m--> 471\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_og_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_og_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    472\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/utils/runnable.py:376\u001B[0m, in \u001B[0;36mRunnableCallable.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    374\u001B[0m         run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(ret)\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 376\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecurse \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, Runnable):\n\u001B[1;32m    378\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "Cell \u001B[0;32mIn[5], line 11\u001B[0m, in \u001B[0;36mcollect_ml_document_content\u001B[0;34m(state)\u001B[0m\n\u001B[1;32m      7\u001B[0m model_artifacts_organizer \u001B[38;5;241m=\u001B[39m ModelArtifactOrganizer(catalog\u001B[38;5;241m=\u001B[39mstate[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcustom_inputs\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcatalog\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      8\u001B[0m                                                    schema\u001B[38;5;241m=\u001B[39mstate[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcustom_inputs\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mschema\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      9\u001B[0m                                                    model\u001B[38;5;241m=\u001B[39mstate[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcustom_inputs\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Collect ML model assets\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m artifact_volume_path \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_artifacts_organizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect_mlflow_artifacts\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Create model attributes table, notebook, and image markdown\u001B[39;00m\n\u001B[1;32m     14\u001B[0m model_artifacts_organizer\u001B[38;5;241m.\u001B[39mcreate_model_attributes_md()\n",
      "File \u001B[0;32m~/workspace/genai_dev/src/model_artifacts_organizer.py:21\u001B[0m, in \u001B[0;36mModelArtifactOrganizer.collect_mlflow_artifacts\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcollect_mlflow_artifacts\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[0;32m---> 21\u001B[0m     model_version \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_model_version_by_alias\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_full_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mproduction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m     run_id \u001B[38;5;241m=\u001B[39m model_version\u001B[38;5;241m.\u001B[39mrun_id\n\u001B[1;32m     25\u001B[0m     destination_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_uc_artifact_folder(\n\u001B[1;32m     26\u001B[0m         volume_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvolume_path, folder_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\n\u001B[1;32m     27\u001B[0m     )\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/tracking/client.py:5233\u001B[0m, in \u001B[0;36mMlflowClient.get_model_version_by_alias\u001B[0;34m(self, name, alias)\u001B[0m\n\u001B[1;32m   5149\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Get the model version instance by name and alias.\u001B[39;00m\n\u001B[1;32m   5150\u001B[0m \n\u001B[1;32m   5151\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5230\u001B[0m \u001B[38;5;124;03m    Aliases: [\"test-alias\"]\u001B[39;00m\n\u001B[1;32m   5231\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   5232\u001B[0m _validate_model_name(name)\n\u001B[0;32m-> 5233\u001B[0m mv \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_registry_client\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_model_version_by_alias\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malias\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5235\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_prompt_tag(mv\u001B[38;5;241m.\u001B[39m_tags):\n\u001B[1;32m   5236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m _model_not_found(name)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/tracking/_model_registry/client.py:433\u001B[0m, in \u001B[0;36mModelRegistryClient.get_model_version_by_alias\u001B[0;34m(self, name, alias)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mget_model_version_by_alias\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, alias):\n\u001B[1;32m    423\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get the model version instance by name and alias.\u001B[39;00m\n\u001B[1;32m    424\u001B[0m \n\u001B[1;32m    425\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    431\u001B[0m \n\u001B[1;32m    432\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 433\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_model_version_by_alias\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/store/model_registry/rest_store.py:473\u001B[0m, in \u001B[0;36mRestStore.get_model_version_by_alias\u001B[0;34m(self, name, alias)\u001B[0m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;124;03mGet the model version instance by name and alias.\u001B[39;00m\n\u001B[1;32m    464\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    470\u001B[0m \u001B[38;5;124;03m    A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.\u001B[39;00m\n\u001B[1;32m    471\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    472\u001B[0m req_body \u001B[38;5;241m=\u001B[39m message_to_json(GetModelVersionByAlias(name\u001B[38;5;241m=\u001B[39mname, alias\u001B[38;5;241m=\u001B[39malias))\n\u001B[0;32m--> 473\u001B[0m response_proto \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_endpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mGetModelVersionByAlias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq_body\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ModelVersion\u001B[38;5;241m.\u001B[39mfrom_proto(response_proto\u001B[38;5;241m.\u001B[39mmodel_version)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/store/model_registry/base_rest_store.py:44\u001B[0m, in \u001B[0;36mBaseRestStore._call_endpoint\u001B[0;34m(self, api, json_body, call_all_endpoints, extra_headers)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     43\u001B[0m     endpoint, method \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_endpoint_from_method(api)\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall_endpoint\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_host_creds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_proto\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_headers\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:392\u001B[0m, in \u001B[0;36mcall_endpoint\u001B[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001B[0m\n\u001B[1;32m    389\u001B[0m     call_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjson\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m json_body\n\u001B[1;32m    390\u001B[0m     response \u001B[38;5;241m=\u001B[39m http_request(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcall_kwargs)\n\u001B[0;32m--> 392\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mverify_rest_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    393\u001B[0m response_to_parse \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mtext\n\u001B[1;32m    394\u001B[0m js_dict \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(response_to_parse)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:249\u001B[0m, in \u001B[0;36mverify_rest_response\u001B[0;34m(response, endpoint)\u001B[0m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:\n\u001B[1;32m    248\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _can_parse_as_json_object(response\u001B[38;5;241m.\u001B[39mtext):\n\u001B[0;32m--> 249\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m RestException(json\u001B[38;5;241m.\u001B[39mloads(response\u001B[38;5;241m.\u001B[39mtext))\n\u001B[1;32m    250\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    251\u001B[0m         base_msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    252\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAPI request to endpoint \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mendpoint\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    253\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfailed with error code \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m != 200\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    254\u001B[0m         )\n",
      "\u001B[0;31mRestException\u001B[0m: RESOURCE_DOES_NOT_EXIST: Registered Model with name=qyu.dbdemos_fs_travel.dbdemos_fs_travel_model not found"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Trace(request_id=25f19ec2b177425c9cd521251ebb4f41)"
      ],
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=25f19ec2b177425c9cd521251ebb4f41&amp;experiment_id=328097605715257401&amp;version=2.21.3\"\n",
       "  />\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T01:42:35.551887Z",
     "start_time": "2025-03-03T01:42:24.844308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mlflow\n",
    "from databricks_langchain import VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "\n",
    "\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\n",
    "for tool in tools:\n",
    "    if isinstance(tool, VectorSearchRetrieverTool):\n",
    "        resources.extend(tool.resources)\n",
    "    elif isinstance(tool, UnityCatalogTool):\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"agent\",\n",
    "        python_model=\"../src/agent.py\",\n",
    "        pip_requirements=[\n",
    "            \"mlflow\",\n",
    "            \"langchain\",\n",
    "            \"langgraph<0.3.0\",\n",
    "            \"databricks-langchain\",\n",
    "            \"unitycatalog-langchain[databricks]\",\n",
    "            \"pydantic\",\n",
    "        ],\n",
    "        resources=resources,\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True to VectorSearchClient().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/02 17:42:27 INFO mlflow.pyfunc: Predicting on input example to validate output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True to VectorSearchClient().\n",
      " View run gentle-donkey-705 at: https://adb-984752964297111.11.azuredatabricks.net/#/experiments/738407902153498034/runs/68035f9acf4647e9b817a65d0328ac96\n",
      " View experiment at: https://adb-984752964297111.11.azuredatabricks.net/#/experiments/738407902153498034\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

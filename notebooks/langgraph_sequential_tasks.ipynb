{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58635464-8094-4a92-b7b4-0618fb8e92fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# This Notebook is to Experiment LangGraph Agents\n",
    "\n",
    "The Sequential Tasks are:\n",
    "- Collect Model information from MLFlow run\n",
    "- Collect the notebook information\n",
    "- Write a ML document draft\n",
    "- Review the draft and create a final version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c6a034e-4784-46d6-96c6-ac0bd3c8e5d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt --quiet\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T23:00:27.814326Z",
     "start_time": "2025-04-19T23:00:27.785157Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2aa171e-2df5-4412-9e42-2ca2d765dae8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "local = False \n",
    "\n",
    "if local:\n",
    "    from databricks.connect import DatabricksSession\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    spark = DatabricksSession.builder.getOrCreate()\n",
    "    load_dotenv('../.env')\n",
    "\n",
    "    DATABRICKS_HOST = os.getenv('host')\n",
    "    DATABRICKS_TOKEN = os.getenv('token')\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "else:\n",
    "    DATABRICKS_HOST = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().get()\n",
    "    OPENAI_API_KEY = dbutils.secrets.get(\"databricks_token_qyu\", \"OpenAi\")\n",
    "\n",
    "\n",
    "print(f\"host: {DATABRICKS_HOST}\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0c3593b-7a01-455d-805a-2d351924446c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Set the ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:39:52.678800Z",
     "start_time": "2025-04-19T22:39:52.659579Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bc44860-fe69-4e87-ac9b-7ebc16474491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from unitycatalog.ai.core.base import set_uc_function_client\n",
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient\n",
    "\n",
    "client = DatabricksFunctionClient()\n",
    "set_uc_function_client(client)\n",
    "\n",
    "CATALOG = 'qyu'\n",
    "SCHEMA = 'dbdemos_fs_travel'\n",
    "model = 'dbdemos_fs_travel_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b318d7c8-f2e4-4c62-9500-1b61564233fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create LangGraph Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:39:58.740778Z",
     "start_time": "2025-04-19T22:39:57.303887Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2ed0608-d8ca-4b91-b775-8344e6af9a86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any, Generator, Optional, Sequence, Union, TypedDict, Dict, List\n",
    "\n",
    "import mlflow\n",
    "from databricks_langchain import ChatDatabricks, VectorSearchRetrieverTool\n",
    "from databricks_langchain.uc_ai import (\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "\n",
    "if local:\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_registry_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"langgraph_test\")\n",
    "else:\n",
    "    mlflow.set_tracking_uri(\"databricks\")\n",
    "    mlflow.set_registry_uri(\"databricks-uc\")\n",
    "    mlflow.set_experiment(\"/Users/q.yu@databricks.com/ML_experiments/ml_doc_agent\")\n",
    "\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:40:00.294107Z",
     "start_time": "2025-04-19T22:40:00.281979Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b24cc37-2e9d-4368-beba-58c2f3dfbb2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "LLM = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "# Prompts\n",
    "WRITTER_PROMPT = \"\"\"\n",
    "      You are a technical document writer with experience in creating detailed technical document\n",
    "       for machine learning models. You are skilled in organizing complex information and\n",
    "      presenting it in a clear and concise manner. You use content from machine learning\n",
    "      notebooks, model experiment run information, model explainability plots, model artifacts\n",
    "      files to craft the detailed machine learning technical document. Always remember:\n",
    "      1. Make sure section titles and subtitles are properly named\n",
    "      2. Have a hign-level description for each section before the technical details\n",
    "      3. Use markdown format for writting the document\n",
    "\"\"\"\n",
    "\n",
    "REVIEWER_PROMPT = \"\"\"\n",
    "      You are a technical document editor with experience in editing machine learning technical\n",
    "      documents. You are skilled in reviewing and refining content to ensure accuracy, clarity,\n",
    "      and consistency. You write the edited technical document and produce a final version of the document.\n",
    "      always remember:\n",
    "      1. check for grammar, style and accuracy\n",
    "      2. Ensure that the document is well-structured and easy to follow\n",
    "      3. Use markdown format for writing the document\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:40:01.825660Z",
     "start_time": "2025-04-19T22:40:01.510637Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3162123-a022-4e64-ae02-b420c93f304c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from src.model_artifacts_organizer import ModelArtifactOrganizer\n",
    "from src.file_management_utils import recursive_file_loader\n",
    "\n",
    "\n",
    "def collect_ml_document_content(state: ChatAgentState) -> dict:\n",
    "    \"\"\"Process the content organization.\"\"\"\n",
    "    model_artifacts_organizer = ModelArtifactOrganizer(catalog=state['custom_inputs']['catalog'],\n",
    "                                                       schema=state['custom_inputs']['schema'],\n",
    "                                                       model=state['custom_inputs']['model'])\n",
    "    # Collect ML model assets\n",
    "    artifact_volume_path = model_artifacts_organizer.collect_mlflow_artifacts()\n",
    "\n",
    "    # Create model attributes table, notebook, and image markdown\n",
    "    model_artifacts_organizer.create_model_attributes_md()\n",
    "    model_artifacts_organizer.notebook_to_md()\n",
    "    model_artifacts_organizer.image_file_to_md()\n",
    "\n",
    "    # Collect content source files\n",
    "    doc_contents = recursive_file_loader(artifact_volume_path)\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a MLops experts\"},\n",
    "                {\"role\": \"user\", \"content\": \"Collected ML model assets, generated model \"\n",
    "                                            \"attributes table, notebook, and image markdown.\"}]\n",
    "\n",
    "    # Create a summary of all files\n",
    "    files_content = \"\\n\\n\".join([\n",
    "        f\"File: {doc.metadata['relative_path']}\\nType: {doc.metadata['file_type']}\\nContent: {doc.page_content}\"\n",
    "        for doc in doc_contents\n",
    "    ])\n",
    "    custom_outputs = state.get('custom_outputs', {}).copy()\n",
    "    custom_outputs['source_contents'] = files_content\n",
    "    state[\"custom_outputs\"]['source_contents'] = files_content\n",
    "    messages.append({\"role\": \"system\", \"content\": files_content})\n",
    "\n",
    "    return {\"messages\": messages, \"custom_outputs\": custom_outputs}\n",
    "\n",
    "\n",
    "def write_doc_draft(state: ChatAgentState, config: RunnableConfig) -> dict:\n",
    "    \"\"\"write the ml document draft\"\"\"\n",
    "\n",
    "    files_content = state.get(\"custom_outputs\", {}).get(\"source_contents\", \"No content found\")\n",
    "    content_message = {\"role\": \"user\", \"content\": f\"Here is the content of the files: {files_content}\"}\n",
    "   # Generate the outline\n",
    "    preprocessor = RunnableLambda(\n",
    "            lambda state: [{\"role\": \"system\", \"content\": WRITTER_PROMPT}]\n",
    "                          + state[\"messages\"] + [content_message]\n",
    "    )\n",
    "\n",
    "    model_runnable = preprocessor | LLM\n",
    "    response = model_runnable.invoke(state, config)\n",
    "\n",
    "    custom_outputs = state.get('custom_outputs', {}).copy()\n",
    "    custom_outputs['document_draft'] = response.content\n",
    "    state[\"custom_outputs\"]['document_draft'] = response.content\n",
    "\n",
    "    return {\"messages\": [response.dict()], \"custom_outputs\": custom_outputs}\n",
    "\n",
    "def review_doc_draft(state: ChatAgentState, config: RunnableConfig) -> dict:\n",
    "    \"\"\"review the ml document draft and write the final version\"\"\"\n",
    "\n",
    "    doc_draft = state.get(\"custom_outputs\", {}).get(\"document_draft\", \"No draft available\")\n",
    "    draft_message = {\"role\": \"user\", \"content\": f\"Here is the draft of the ml document: \"\n",
    "                                                f\"{doc_draft}\"}\n",
    "    # Generate the outline\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: [{\"role\": \"system\", \"content\": REVIEWER_PROMPT}]\n",
    "                      + state[\"messages\"] + [draft_message]\n",
    "    )\n",
    "    model_runnable = preprocessor | LLM\n",
    "    response = model_runnable.invoke(state, config)\n",
    "\n",
    "    custom_outputs = state.get('custom_outputs', {}).copy()\n",
    "    custom_outputs['final_document'] = response.content\n",
    "    state[\"custom_outputs\"]['final_document'] = response.content\n",
    "\n",
    "    return {\"messages\": [response.dict()], \"custom_outputs\": custom_outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:40:03.985647Z",
     "start_time": "2025-04-19T22:40:03.979838Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "257a5686-cdaa-4d6d-b463-38658a1141c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "workflow = StateGraph(ChatAgentState)\n",
    "\n",
    "# Create nodes\n",
    "workflow.add_node(\"collect_ml_document_content\", collect_ml_document_content)\n",
    "workflow.add_node(\"write_doc_draft\", RunnableLambda(write_doc_draft))\n",
    "workflow.add_node(\"review_doc_draft\", RunnableLambda(review_doc_draft))\n",
    "\n",
    "# Create edges\n",
    "workflow.set_entry_point(\"collect_ml_document_content\")\n",
    "workflow.add_edge(\"collect_ml_document_content\", \"write_doc_draft\")\n",
    "workflow.add_edge(\"write_doc_draft\", \"review_doc_draft\")\n",
    "workflow.add_edge(\"review_doc_draft\", END)\n",
    "\n",
    "auto_ml_doc_flow = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:40:05.180472Z",
     "start_time": "2025-04-19T22:40:04.976443Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86fbb53c-62a6-4a7d-a7c7-2ad6f98d70e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(auto_ml_doc_flow.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:40:08.870976Z",
     "start_time": "2025-04-19T22:40:08.865529Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "473b68fd-54c1-4808-9ec2-e6d6988b5f6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class LangGraphChatAgent(ChatAgent):\n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "            self,\n",
    "            messages: list[ChatAgentMessage],\n",
    "            context: Optional[ChatContext] = None,\n",
    "            custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        if context:\n",
    "            request[\"context\"] = context\n",
    "\n",
    "        if custom_inputs:\n",
    "            request[\"custom_inputs\"] = custom_inputs\n",
    "\n",
    "        messages = []\n",
    "        custom_outputs = {}\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                messages.extend(\n",
    "                    ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "                )\n",
    "                if \"custom_outputs\" in node_data:\n",
    "                    custom_outputs.update(node_data[\"custom_outputs\"])\n",
    "\n",
    "        return ChatAgentResponse(messages=messages, custom_outputs=custom_outputs)\n",
    "\n",
    "    def predict_stream(\n",
    "            self,\n",
    "            messages: list[ChatAgentMessage],\n",
    "            context: Optional[ChatContext] = None,\n",
    "            custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        if context:\n",
    "            request[\"context\"] = context\n",
    "\n",
    "        if custom_inputs:\n",
    "            request[\"custom_inputs\"] = custom_inputs\n",
    "\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                yield from (\n",
    "                    ChatAgentChunk(**{\"delta\": msg}) for msg in node_data[\"messages\"]\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:40:10.853094Z",
     "start_time": "2025-04-19T22:40:10.705025Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dfa1850-d3e4-48d9-b352-d8c1ae6ce10a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AGENT = LangGraphChatAgent(auto_ml_doc_flow)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:40:14.624745Z",
     "start_time": "2025-04-19T22:40:12.041403Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "925fd627-825e-42a6-bda7-2ba000b7aa3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"Create a comprehensive ML document\"}],\n",
    "              \"custom_inputs\": {\"catalog\": CATALOG, \"schema\": SCHEMA, \"model\": model}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T01:42:35.551887Z",
     "start_time": "2025-03-03T01:42:24.844308Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e7960d1-ba90-4b55-ae2b-2fd1bdc8a616",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from databricks_langchain import VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "\n",
    "\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\n",
    "for tool in tools:\n",
    "    if isinstance(tool, VectorSearchRetrieverTool):\n",
    "        resources.extend(tool.resources)\n",
    "    elif isinstance(tool, UnityCatalogTool):\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"agent\",\n",
    "        python_model=\"../src/agent.py\",\n",
    "        pip_requirements=[\n",
    "            \"mlflow\",\n",
    "            \"langchain\",\n",
    "            \"langgraph<0.3.0\",\n",
    "            \"databricks-langchain\",\n",
    "            \"unitycatalog-langchain[databricks]\",\n",
    "            \"pydantic\",\n",
    "        ],\n",
    "        resources=resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80e8187a-4adf-4175-816b-418d65d2e084",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "langgraph_sequential_tasks",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d46d7393-be29-4029-badc-1388d8d0ea57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# This Notebook is to test the branch tasks of LangGraph\n",
    "\n",
    "The branch tasks are:\n",
    "\n",
    "* A router agent to determine the task\n",
    "* 2 tool calling agents to perform task routed from the router agent\n",
    "* This is chat app instead of a 1 pass tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8b302aa-1601-4224-a178-06e82800ccda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt --quiet\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:58:54.860923Z",
     "start_time": "2025-04-20T21:58:54.839965Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31f7ee5b-1773-421c-a106-1daa92ea06c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "local = False\n",
    "\n",
    "if local:\n",
    "    from databricks.connect import DatabricksSession\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    spark = DatabricksSession.builder.getOrCreate()\n",
    "    load_dotenv('../.env')\n",
    "\n",
    "    DATABRICKS_HOST = os.getenv('host')\n",
    "    DATABRICKS_TOKEN = os.getenv('token')\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "else:\n",
    "    DATABRICKS_HOST = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().get()\n",
    "    OPENAI_API_KEY = dbutils.secrets.get(\"databricks_token_qyu\", \"OpenAi\")\n",
    "\n",
    "print(f\"host: {DATABRICKS_HOST}\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:58:55.485286Z",
     "start_time": "2025-04-20T21:58:55.466981Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a98214fa-9d3c-4e44-8c9f-bb6f245d7ce5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from unitycatalog.ai.core.base import set_uc_function_client\n",
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient\n",
    "\n",
    "client = DatabricksFunctionClient()\n",
    "set_uc_function_client(client)\n",
    "\n",
    "CATALOG = 'dhuang'\n",
    "SCHEMA = 'insurance_agent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:58:56.488381Z",
     "start_time": "2025-04-20T21:58:56.248271Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b579986-f262-44ce-a736-ca2d948bc5c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any, Generator, Optional, Sequence, Union, TypedDict, Dict, List\n",
    "from typing_extensions import Literal\n",
    "\n",
    "import mlflow\n",
    "from pydantic import BaseModel, Field\n",
    "from databricks_langchain import ChatDatabricks, VectorSearchRetrieverTool\n",
    "from databricks_langchain.uc_ai import (\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage\n",
    "from langchain_core.tools import BaseTool\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "\n",
    "if local:\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_registry_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"langgraph_test\")\n",
    "else:\n",
    "    mlflow.set_tracking_uri(\"databricks\")\n",
    "    mlflow.set_registry_uri(\"databricks-uc\")\n",
    "    mlflow.set_experiment(\"/Users/q.yu@databricks.com/ML_experiments/insurance_chat_agents\")\n",
    "\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:58:57.212230Z",
     "start_time": "2025-04-20T21:58:57.193846Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60061f62-f019-48f4-aff0-783d69663241",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-3-7-sonnet\"\n",
    "LLM = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "RECOMMENDED_PROMPT_PREFIX = \"\"\"\n",
    "    # System context\n",
    "    You are part of a multi-agent system, designed to make agent coordination and execution easy.\n",
    "    Agents uses two primary abstraction: **Agents** and **Handoffs**.\n",
    "    An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate.\n",
    "    Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`.\n",
    "    Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\n",
    "\"\"\"\n",
    "\n",
    "TRIAGE_PROMPT = \"\"\"\n",
    "    You are a helpful triaging agent.\n",
    "    You can use your tools to delegate questions to other appropriate agents.\n",
    "    If the customer does not have anymore questions, wish them a goodbye and a good rest of their day.\n",
    "\"\"\"\n",
    "\n",
    "CLAIMS_DETAIL_RETRIEVAL_PROMPT = \"\"\"\n",
    "    You are a claims details retrieval agent.\n",
    "    If you are speaking to a customer, you probably were transferred to you from the triage agent.\n",
    "    Use the following routine to support the customer.\n",
    "    # Routine:\n",
    "    1. Identify the last question asked by the customer.\n",
    "    2. Use the search tools to retrieve data about a claim. Do not rely on your own knowledge.\n",
    "    3. If you cannot answer the question, transfer back to the triage agent.\n",
    "\"\"\"\n",
    "\n",
    "POLICY_QA_AGENT_PROMPT = \"\"\"\n",
    "    You are an insurance policy Q&A agent.\n",
    "    If you are speaking to a customer, you probably were transferred to you from the triage agent.\n",
    "    Use the following routine to support the customer.\n",
    "    # Routine:\n",
    "    1. Identify the last question asked by the customer.\n",
    "    2. Use the search tools to answer the question about their policy. Do not rely on your own knowledge.\n",
    "    3. If you cannot answer the question, transfer back to the triage agent.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f89122d6-fb9f-4b64-bd12-fb3e125a2743",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create a Tool Calling Agent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:59:00.635188Z",
     "start_time": "2025-04-20T21:59:00.610818Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55865fd8-db58-4108-aaa2-3b4824fd8f46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_tool_calling_agent(model: LanguageModelLike,\n",
    "                              tools: Union[ToolNode, Sequence[BaseTool]],\n",
    "                              system_prompt: Optional[str] = None,\n",
    "                              ) -> CompiledGraph:\n",
    "    \"\"\"Creates an agent for handling claim detail retrieval requests.\"\"\"\n",
    "\n",
    "    # Bind tools to the model\n",
    "    model = model.bind_tools(tools)\n",
    "\n",
    "    # Define the function that determines which node to go to\n",
    "    def should_continue(state: ChatAgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        last_message = messages[-1]\n",
    "        # If there are function calls, continue. else, end\n",
    "        if last_message.get(\"tool_calls\"):\n",
    "            return \"continue\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "\n",
    "    # Create the message preprocessor with system prompt\n",
    "    if system_prompt:\n",
    "        preprocessor = RunnableLambda(\n",
    "            lambda state: [{\"role\": \"system\", \"content\": system_message}]\n",
    "                          + state[\"messages\"]\n",
    "        )\n",
    "    else:\n",
    "        preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "    model_runnable = preprocessor | model\n",
    "\n",
    "    # Define the call_model function\n",
    "    def call_model(\n",
    "            state: ChatAgentState,\n",
    "            config: RunnableConfig\n",
    "    ):\n",
    "        response = model_runnable.invoke(state, config)\n",
    "        return {\"messages\": state[\"messages\"] + [response]}\n",
    "\n",
    "    # Create the workflow graph\n",
    "    workflow = StateGraph(ChatAgentState)\n",
    "    workflow.add_node(\"agent\", RunnableLambda(call_model))\n",
    "    workflow.add_node(\"tools\", ChatAgentToolNode(tools))\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"continue\": \"tools\",\n",
    "            \"end\": END,\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "    return workflow.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "587e099f-8a30-4cc9-add4-4e1635f0dda2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create a Triage Agent (Rounter) Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:59:04.340700Z",
     "start_time": "2025-04-20T21:59:04.317305Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df4fd965-a6a4-4af4-afb2-e4edf2def4c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_triage_agent(model: LanguageModelLike,\n",
    "                        system_prompt: Optional[str] = None,\n",
    "                        ) -> RunnableLambda:\n",
    "    \"\"\"Create a triage agent to route the input to the appropriate tool agent\"\"\"\n",
    "\n",
    "    def triage_query(state: ChatAgentState, config: RunnableConfig):\n",
    "        user_messages = [msg for msg in state['messages'] if msg.get(\"role\") == \"user\"]\n",
    "\n",
    "        if not user_messages:\n",
    "            return {\"route\": \"need clarification\"}\n",
    "\n",
    "        latest_user_msg = user_messages[-1]\n",
    "        user_query = latest_user_msg.get(\"content\", \"\")\n",
    "\n",
    "        # Prepare classification request\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"customer question: {user_query}\"}\n",
    "        ]\n",
    "\n",
    "        # Get classification from the model\n",
    "        response = model.invoke(messages)\n",
    "        classification = response.content.strip().lower()\n",
    "\n",
    "        # Determine routing based on classification\n",
    "        if \"claim\" in classification:\n",
    "            print(\"[DEBUG] route to claim agent\")\n",
    "            return {\"route\": \"claim_detail_retrieval\"}\n",
    "        elif \"policy\" in classification:\n",
    "            print(\"[DEBUG] route to policy agent\")\n",
    "            return {\"route\": \"policy_questions\"}\n",
    "        else:\n",
    "            print(\"[DEBUG] route back to triage agent\")\n",
    "            return {\"route\": \"unknown\"}\n",
    "\n",
    "    return RunnableLambda(triage_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea5f738c-4110-4867-af50-7ecbf5564407",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create multi-agent workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:59:06.995094Z",
     "start_time": "2025-04-20T21:59:06.431098Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d67e77b-2e5d-42be-99c7-fedab288ae10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "uc_tool_name = [f\"{CATALOG}.{SCHEMA}.{func.name}\" for func in client.list_functions(catalog=CATALOG,\n",
    "                                                                                    schema=SCHEMA)]\n",
    "selected_uc_tool_names = uc_tool_name[:2]\n",
    "print(selected_uc_tool_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:59:08.800934Z",
     "start_time": "2025-04-20T21:59:08.352082Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d7d0853-e4e3-4663-ae69-411526d728df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tools = []\n",
    "uc_toolkit = UCFunctionToolkit(function_names=selected_uc_tool_names)\n",
    "tools.extend(uc_toolkit.tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:00:42.200010Z",
     "start_time": "2025-04-20T22:00:42.075675Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c92a9a10-05a3-4e2f-829b-44994a5deada",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "triage_agent = create_triage_agent(LLM, TRIAGE_PROMPT)\n",
    "claim_agent = create_tool_calling_agent(LLM, [tools[1]], CLAIMS_DETAIL_RETRIEVAL_PROMPT)\n",
    "policy_agent = create_tool_calling_agent(LLM, [tools[0]], POLICY_QA_AGENT_PROMPT)\n",
    "\n",
    "def route_to_agent(state: ChatAgentState):\n",
    "    route = state.get(\"route\")\n",
    "    if route == \"claim_detail_retrieval\":\n",
    "        return \"claim_agent\"\n",
    "    elif route == \"policy_questions\":\n",
    "        return \"policy_agent\"\n",
    "    elif route == 'unknown':\n",
    "        return \"triage_agent\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63553f4a-8163-4fe6-99e0-0e21980c6da0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create the multi-agent workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:00:44.492192Z",
     "start_time": "2025-04-20T22:00:44.470510Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5141ae61-82a3-4d13-9286-eb04f84de5ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "workflow = StateGraph(ChatAgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"triage_agent\", triage_agent)\n",
    "workflow.add_node(\"claim_agent\", claim_agent)\n",
    "workflow.add_node(\"policy_agent\", policy_agent)\n",
    "\n",
    "# Add edges\n",
    "workflow.set_entry_point(\"triage_agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"triage_agent\",\n",
    "    route_to_agent,\n",
    "    {\n",
    "        \"claim_detail_retrieval\": \"claim_agent\",\n",
    "        \"policy_questions\": \"policy_agent\",\n",
    "        \"unkonwn\": \"triage_agent\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"claim_agent\", END)\n",
    "workflow.add_edge(\"policy_agent\", END)\n",
    "\n",
    "# Shall I add these edges to return to the triage agent for new questions?\n",
    "# workflow.add_edge(\"claim_agent\", \"triage_agent\")\n",
    "# workflow.add_edge(\"policy_agent\", \"triage_agent\")\n",
    "\n",
    "insurance_agent_workflow = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:00:46.289845Z",
     "start_time": "2025-04-20T22:00:46.155547Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17de1947-4095-43e3-be43-4f8526d81c9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(insurance_agent_workflow.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6271831b-01fd-404f-8cf6-8aba15223d14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create ChatAgent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:00:49.172766Z",
     "start_time": "2025-04-20T22:00:49.154096Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f84b577-d29c-4319-a100-b706968665ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class InsuranceMultiAgentChatAgent(ChatAgent):\n",
    "    \"\"\"MLflow ChatAgent implementation for the insurance multi-agent workflow.\"\"\"\n",
    "\n",
    "    def __init__(self, agent: CompiledGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: List[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[Dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        \"\"\"Processes a conversation and returns a response.\"\"\"\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        # Execute the workflow\n",
    "        result = self.agent.invoke(request)\n",
    "\n",
    "        # Convert messages to ChatAgentMessage format\n",
    "        response_messages = []\n",
    "        for node_name, node_data in result.items():\n",
    "            if isinstance(node_data, dict) and \"messages\" in node_data:\n",
    "                for msg in node_data[\"messages\"]:\n",
    "                    if isinstance(msg, dict):\n",
    "                        response_messages.append(ChatAgentMessage(**msg))\n",
    "\n",
    "        return ChatAgentResponse(messages=response_messages)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: List[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[Dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        \"\"\"Streams the agent's response.\"\"\"\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        # Stream the workflow execution\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                if isinstance(node_data, dict) and \"messages\" in node_data:\n",
    "                    for msg in node_data[\"messages\"]:\n",
    "                        if isinstance(msg, dict):\n",
    "                            yield ChatAgentChunk(delta=msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:00:51.949306Z",
     "start_time": "2025-04-20T22:00:51.929518Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cac44f7e-eab7-45a7-bbd3-6f668c9d6931",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AGENT = InsuranceMultiAgentChatAgent(insurance_agent_workflow)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:00:56.096869Z",
     "start_time": "2025-04-20T22:00:53.264057Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0947cb04-0a4a-4a10-85ea-c4108144a968",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"hi, id like to check on my existing claims\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a871d206-e088-4e69-9e2b-771bc69df26d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "langgraph_branch_tasks",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

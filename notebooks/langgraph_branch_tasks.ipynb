{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This Notebook is to test the branch tasks of LangGraph\n",
    "\n",
    "The branch tasks are:\n",
    "\n",
    "* A router agent to determine the task\n",
    "* 2 tool calling agents to perform task routed from the router agent\n",
    "* This is chat app instead of a 1 pass tasks"
   ],
   "id": "8d539e48008b57c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain.agents.agent import RunnableAgent\n",
    "from langgraph.prebuilt import ToolNode\n",
    "%pip install -r ../requirements.txt --quiet\n",
    "%restart_python"
   ],
   "id": "5fd87754fe6e6d36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:58:54.860923Z",
     "start_time": "2025-04-20T21:58:54.839965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "local = True\n",
    "\n",
    "if local:\n",
    "    from databricks.connect import DatabricksSession\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    spark = DatabricksSession.builder.getOrCreate()\n",
    "    load_dotenv('../.env')\n",
    "\n",
    "    DATABRICKS_HOST = os.getenv('host')\n",
    "    DATABRICKS_TOKEN = os.getenv('token')\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "else:\n",
    "    DATABRICKS_HOST = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().get()\n",
    "    OPENAI_API_KEY = dbutils.secrets.get(\"databricks_token_qyu\", \"OpenAi\")\n",
    "\n",
    "print(f\"host: {DATABRICKS_HOST}\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "f77c8e2d56c8d95d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host: adb-984752964297111.11.azuredatabricks.net\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:58:55.485286Z",
     "start_time": "2025-04-20T21:58:55.466981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from unitycatalog.ai.core.base import set_uc_function_client\n",
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient\n",
    "\n",
    "client = DatabricksFunctionClient()\n",
    "set_uc_function_client(client)\n",
    "\n",
    "CATALOG = 'dhuang'\n",
    "SCHEMA = 'insurance_agent'"
   ],
   "id": "e166d030cb2a3d46",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:58:56.488381Z",
     "start_time": "2025-04-20T21:58:56.248271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Any, Generator, Optional, Sequence, Union, TypedDict, Dict, List\n",
    "from typing_extensions import Literal\n",
    "\n",
    "import mlflow\n",
    "from pydantic import BaseModel, Field\n",
    "from databricks_langchain import ChatDatabricks, VectorSearchRetrieverTool\n",
    "from databricks_langchain.uc_ai import (\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage\n",
    "from langchain_core.tools import BaseTool\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "\n",
    "if local:\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_registry_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"langgraph_test\")\n",
    "else:\n",
    "    mlflow.set_tracking_uri(\"databricks\")\n",
    "    mlflow.set_registry_uri(\"databricks-uc\")\n",
    "    mlflow.set_experiment(\"/Users/q.yu@databricks.com/ML_experiments/ml_doc_agent\")\n",
    "\n",
    "mlflow.langchain.autolog()"
   ],
   "id": "53f104389047d30a",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:58:57.212230Z",
     "start_time": "2025-04-20T21:58:57.193846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-3-7-sonnet\"\n",
    "LLM = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "RECOMMENDED_PROMPT_PREFIX = \"\"\"\n",
    "    # System context\n",
    "    You are part of a multi-agent system, designed to make agent coordination and execution easy.\n",
    "    Agents uses two primary abstraction: **Agents** and **Handoffs**.\n",
    "    An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate.\n",
    "    Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`.\n",
    "    Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\n",
    "\"\"\"\n",
    "\n",
    "TRIAGE_PROMPT = \"\"\"\n",
    "    You are a helpful triaging agent.\n",
    "    You can use your tools to delegate questions to other appropriate agents.\n",
    "    If the customer does not have anymore questions, wish them a goodbye and a good rest of their day.\n",
    "\"\"\"\n",
    "\n",
    "CLAIMS_DETAIL_RETRIEVAL_PROMPT = \"\"\"\n",
    "    You are a claims details retrieval agent.\n",
    "    If you are speaking to a customer, you probably were transferred to you from the triage agent.\n",
    "    Use the following routine to support the customer.\n",
    "    # Routine:\n",
    "    1. Identify the last question asked by the customer.\n",
    "    2. Use the search tools to retrieve data about a claim. Do not rely on your own knowledge.\n",
    "    3. If you cannot answer the question, transfer back to the triage agent.\n",
    "\"\"\"\n",
    "\n",
    "POLICY_QA_AGENT_PROMPT = \"\"\"\n",
    "    You are an insurance policy Q&A agent.\n",
    "    If you are speaking to a customer, you probably were transferred to you from the triage agent.\n",
    "    Use the following routine to support the customer.\n",
    "    # Routine:\n",
    "    1. Identify the last question asked by the customer.\n",
    "    2. Use the search tools to answer the question about their policy. Do not rely on your own knowledge.\n",
    "    3. If you cannot answer the question, transfer back to the triage agent.\n",
    "\"\"\""
   ],
   "id": "468d2d20c5db3106",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b3/rdsklr3d0s1f_fzq3pg5try40000gp/T/ipykernel_1143/2156233689.py:5: DeprecationWarning: Currently, temperature defaults to 0.0 if not specified. In the next release, temperature will need to be explicitly set. Please update your code to specify a temperature value. Note: If you are using an o1 or o3 model, you need to set temperature=None.\n",
      "  LLM = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create a Tool Calling Agent function",
   "id": "12cb52325c67b7c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:59:00.635188Z",
     "start_time": "2025-04-20T21:59:00.610818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_tool_calling_agent(model: LanguageModelLike,\n",
    "                              tools: Union[ToolNode, Sequence[BaseTool]],\n",
    "                              system_prompt: Optional[str] = None,\n",
    "                              ) -> CompiledGraph:\n",
    "    \"\"\"Creates an agent for handling claim detail retrieval requests.\"\"\"\n",
    "\n",
    "    # Bind tools to the model\n",
    "    model = model.bind_tools(tools)\n",
    "\n",
    "    # Define the function that determines which node to go to\n",
    "    def should_continue(state: ChatAgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        last_message = messages[-1]\n",
    "        # If there are function calls, continue. else, end\n",
    "        if last_message.get(\"tool_calls\"):\n",
    "            return \"continue\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "\n",
    "    # Create the message preprocessor with system prompt\n",
    "    if system_prompt:\n",
    "        preprocessor = RunnableLambda(\n",
    "            lambda state: [{\"role\": \"system\", \"content\": system_message}]\n",
    "                          + state[\"messages\"]\n",
    "        )\n",
    "    else:\n",
    "        preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "    model_runnable = preprocessor | model\n",
    "\n",
    "    # Define the call_model function\n",
    "    def call_model(\n",
    "            state: ChatAgentState,\n",
    "            config: RunnableConfig\n",
    "    ):\n",
    "        response = model_runnable.invoke(state, config)\n",
    "        return {\"messages\": state[\"messages\"] + [response]}\n",
    "\n",
    "    # Create the workflow graph\n",
    "    workflow = StateGraph(ChatAgentState)\n",
    "    workflow.add_node(\"agent\", RunnableLambda(call_model))\n",
    "    workflow.add_node(\"tools\", ChatAgentToolNode(tools))\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"continue\": \"tools\",\n",
    "            \"end\": END,\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "    return workflow.compile()\n"
   ],
   "id": "74be67710e0f1fc7",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Triage Agent (Rounter)",
   "id": "8d16d7c78280a238"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:59:04.340700Z",
     "start_time": "2025-04-20T21:59:04.317305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_triage_agent(model: LanguageModelLike,\n",
    "                        system_prompt: Optional[str] = None,\n",
    "                        ) -> RunnableLambda:\n",
    "    \"\"\"Create a triage agent to route the input to the appropriate tool agent\"\"\"\n",
    "\n",
    "    def triage_query(state: ChatAgentState, config: RunnableConfig):\n",
    "        user_messages = [msg for msg in state['messages'] if msg.get(\"role\") == \"user\"]\n",
    "\n",
    "        if not user_messages:\n",
    "            return {\"route\": \"need clarification\"}\n",
    "\n",
    "        latest_user_msg = user_messages[-1]\n",
    "        user_query = latest_user_msg.get(\"content\", \"\")\n",
    "\n",
    "        # Prepare classification request\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"customer question: {user_query}\"}\n",
    "        ]\n",
    "\n",
    "        # Get classification from the model\n",
    "        response = model.invoke(messages)\n",
    "        classification = response.content.strip().lower()\n",
    "\n",
    "        # Determine routing based on classification\n",
    "        if \"claim\" in classification:\n",
    "            return {\"route\": \"claim_detail_retrieval\"}\n",
    "        elif \"policy\" in classification:\n",
    "            return {\"route\": \"policy_questions\"}\n",
    "        else:\n",
    "            return {\"route\": \"policy_questions\"}\n",
    "\n",
    "    return RunnableLambda(triage_query)"
   ],
   "id": "52de6204b99ac5fd",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create multi-agent workflow",
   "id": "14a27c547480e6d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:59:06.995094Z",
     "start_time": "2025-04-20T21:59:06.431098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "uc_tool_name = [f\"{CATALOG}.{SCHEMA}.{func.name}\" for func in client.list_functions(catalog=CATALOG,\n",
    "                                                                                    schema=SCHEMA)]\n",
    "selected_uc_tool_names = uc_tool_name[:2]\n",
    "print(selected_uc_tool_names)"
   ],
   "id": "b4de8041f3a63534",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dhuang.insurance_agent.policy_docs_vector_search', 'dhuang.insurance_agent.search_claims_details_by_policy_no']\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T21:59:08.800934Z",
     "start_time": "2025-04-20T21:59:08.352082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tools = []\n",
    "uc_toolkit = UCFunctionToolkit(function_names=selected_uc_tool_names)\n",
    "tools.extend(uc_toolkit.tools)"
   ],
   "id": "1c77a570ee3e6242",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:00:42.200010Z",
     "start_time": "2025-04-20T22:00:42.075675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "triage_agent = create_triage_agent(LLM, TRIAGE_PROMPT)\n",
    "claim_agent = create_tool_calling_agent(LLM, [tools[1]], CLAIMS_DETAIL_RETRIEVAL_PROMPT)\n",
    "policy_agent = create_tool_calling_agent(LLM, [tools[0]], POLICY_QA_AGENT_PROMPT)\n",
    "\n",
    "def route_to_agent(state: ChatAgentState):\n",
    "    route = state.get(\"route\")\n",
    "    if route == \"claim_detail_retrieval\":\n",
    "        return \"claim_agent\"\n",
    "    elif route == \"policy_questions\":\n",
    "        return \"policy_agent\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown route: {route}\")"
   ],
   "id": "772a9acc20ab74b3",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create the multi-agent workflow",
   "id": "fe8bc2fba7249e2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:00:44.492192Z",
     "start_time": "2025-04-20T22:00:44.470510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "workflow = StateGraph(ChatAgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"triage_agent\", triage_agent)\n",
    "workflow.add_node(\"claim_agent\", claim_agent)\n",
    "workflow.add_node(\"policy_agent\", policy_agent)\n",
    "\n",
    "# Add edges\n",
    "workflow.set_entry_point(\"triage_agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"triage_agent\",\n",
    "    route_to_agent,\n",
    "    {\n",
    "        \"claim_detail_retrieval\": \"claim_agent\",\n",
    "        \"policy_questions\": \"policy_agent\",\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"claim_agent\", END)\n",
    "workflow.add_edge(\"policy_agent\", END)\n",
    "\n",
    "# Shall I add these edges to return to the triage agent for new questions?\n",
    "# workflow.add_edge(\"claim_agent\", \"triage_agent\")\n",
    "# workflow.add_edge(\"policy_agent\", \"triage_agent\")\n",
    "\n",
    "insurance_agent_workflow = workflow.compile()"
   ],
   "id": "8b057c3df8e10930",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:00:46.289845Z",
     "start_time": "2025-04-20T22:00:46.155547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(insurance_agent_workflow.get_graph().draw_mermaid_png()))"
   ],
   "id": "f4264a8b3d967a4f",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create ChatAgent Model",
   "id": "3eb4b4c164a3a0a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:00:49.172766Z",
     "start_time": "2025-04-20T22:00:49.154096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class InsuranceMultiAgentChatAgent(ChatAgent):\n",
    "    \"\"\"MLflow ChatAgent implementation for the insurance multi-agent workflow.\"\"\"\n",
    "\n",
    "    def __init__(self, agent: CompiledGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: List[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[Dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        \"\"\"Processes a conversation and returns a response.\"\"\"\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        # Execute the workflow\n",
    "        result = self.agent.invoke(request)\n",
    "\n",
    "        # Convert messages to ChatAgentMessage format\n",
    "        response_messages = []\n",
    "        for node_name, node_data in result.items():\n",
    "            if isinstance(node_data, dict) and \"messages\" in node_data:\n",
    "                for msg in node_data[\"messages\"]:\n",
    "                    if isinstance(msg, dict):\n",
    "                        response_messages.append(ChatAgentMessage(**msg))\n",
    "\n",
    "        return ChatAgentResponse(messages=response_messages)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: List[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[Dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        \"\"\"Streams the agent's response.\"\"\"\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        # Stream the workflow execution\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                if isinstance(node_data, dict) and \"messages\" in node_data:\n",
    "                    for msg in node_data[\"messages\"]:\n",
    "                        if isinstance(msg, dict):\n",
    "                            yield ChatAgentChunk(delta=msg)\n"
   ],
   "id": "eadd35b86b3b3a09",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:00:51.949306Z",
     "start_time": "2025-04-20T22:00:51.929518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AGENT = InsuranceMultiAgentChatAgent(insurance_agent_workflow)\n",
    "mlflow.models.set_model(AGENT)"
   ],
   "id": "abf2c66221eae13d",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:00:56.096869Z",
     "start_time": "2025-04-20T22:00:53.264057Z"
    }
   },
   "cell_type": "code",
   "source": "result = AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"hi, id like to check on my existing claims\"}]})",
   "id": "d46deb6e56d3634",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown route: None",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[61], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mAGENT\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhi, id like to check on my existing claims\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/pyfunc/utils/data_validation.py:119\u001B[0m, in \u001B[0;36mwrap_non_list_predict_pydantic.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    117\u001B[0m     param_names \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39msignature(func)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mkeys() \u001B[38;5;241m-\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m    118\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m {k: \u001B[38;5;28mgetattr\u001B[39m(pydantic_obj, k) \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m param_names}\n\u001B[0;32m--> 119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, pydantic_obj)\n",
      "Cell \u001B[0;32mIn[59], line 17\u001B[0m, in \u001B[0;36mInsuranceMultiAgentChatAgent.predict\u001B[0;34m(self, messages, context, custom_inputs)\u001B[0m\n\u001B[1;32m     14\u001B[0m request \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_messages_to_dict(messages)}\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Execute the workflow\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Convert messages to ChatAgentMessage format\u001B[39;00m\n\u001B[1;32m     20\u001B[0m response_messages \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:483\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    479\u001B[0m call_original \u001B[38;5;241m=\u001B[39m update_wrapper_extended(call_original, original)\n\u001B[1;32m    481\u001B[0m event_logger\u001B[38;5;241m.\u001B[39mlog_patch_function_start(args, kwargs)\n\u001B[0;32m--> 483\u001B[0m \u001B[43mpatch_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcall_original\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    485\u001B[0m session\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    486\u001B[0m event_logger\u001B[38;5;241m.\u001B[39mlog_patch_function_success(args, kwargs)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/langchain/_langchain_autolog.py:74\u001B[0m, in \u001B[0;36mpatched_inference\u001B[0;34m(func_name, original, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     72\u001B[0m         _log_optional_artifacts(config, run_id, result, \u001B[38;5;28mself\u001B[39m, func_name, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 74\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_invoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/langchain/_langchain_autolog.py:66\u001B[0m, in \u001B[0;36mpatched_inference.<locals>._invoke\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_invoke\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m disable_patching():\n\u001B[0;32m---> 66\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:474\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001B[0;34m(*og_args, **og_kwargs)\u001B[0m\n\u001B[1;32m    471\u001B[0m         original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n\u001B[1;32m    472\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n\u001B[0;32m--> 474\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall_original_fn_with_event_logging\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_original_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mog_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mog_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:425\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001B[0;34m(original_fn, og_args, og_kwargs)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    423\u001B[0m     event_logger\u001B[38;5;241m.\u001B[39mlog_original_function_start(og_args, og_kwargs)\n\u001B[0;32m--> 425\u001B[0m     original_fn_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mog_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mog_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    427\u001B[0m     event_logger\u001B[38;5;241m.\u001B[39mlog_original_function_success(og_args, og_kwargs)\n\u001B[1;32m    428\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_fn_result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:471\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001B[0;34m(*_og_args, **_og_kwargs)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001B[39;00m\n\u001B[1;32m    464\u001B[0m \u001B[38;5;66;03m# during original function execution, even if silent mode is enabled\u001B[39;00m\n\u001B[1;32m    465\u001B[0m \u001B[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001B[39;00m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001B[39;00m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m NonMlflowWarningsBehaviorForCurrentThread(\n\u001B[1;32m    468\u001B[0m     disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    469\u001B[0m     reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    470\u001B[0m ):\n\u001B[0;32m--> 471\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_og_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_og_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    472\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2718\u001B[0m, in \u001B[0;36mPregel.invoke\u001B[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001B[0m\n\u001B[1;32m   2716\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2717\u001B[0m     chunks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m-> 2718\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream(\n\u001B[1;32m   2719\u001B[0m     \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   2720\u001B[0m     config,\n\u001B[1;32m   2721\u001B[0m     stream_mode\u001B[38;5;241m=\u001B[39mstream_mode,\n\u001B[1;32m   2722\u001B[0m     output_keys\u001B[38;5;241m=\u001B[39moutput_keys,\n\u001B[1;32m   2723\u001B[0m     interrupt_before\u001B[38;5;241m=\u001B[39minterrupt_before,\n\u001B[1;32m   2724\u001B[0m     interrupt_after\u001B[38;5;241m=\u001B[39minterrupt_after,\n\u001B[1;32m   2725\u001B[0m     checkpoint_during\u001B[38;5;241m=\u001B[39mcheckpoint_during,\n\u001B[1;32m   2726\u001B[0m     debug\u001B[38;5;241m=\u001B[39mdebug,\n\u001B[1;32m   2727\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   2728\u001B[0m ):\n\u001B[1;32m   2729\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   2730\u001B[0m         latest \u001B[38;5;241m=\u001B[39m chunk\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2356\u001B[0m, in \u001B[0;36mPregel.stream\u001B[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001B[0m\n\u001B[1;32m   2350\u001B[0m     \u001B[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001B[39;00m\n\u001B[1;32m   2351\u001B[0m     \u001B[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001B[39;00m\n\u001B[1;32m   2352\u001B[0m     \u001B[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001B[39;00m\n\u001B[1;32m   2353\u001B[0m     \u001B[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001B[39;00m\n\u001B[1;32m   2354\u001B[0m     \u001B[38;5;66;03m# with channel updates applied only at the transition between steps.\u001B[39;00m\n\u001B[1;32m   2355\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m loop\u001B[38;5;241m.\u001B[39mtick(input_keys\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_channels):\n\u001B[0;32m-> 2356\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m runner\u001B[38;5;241m.\u001B[39mtick(\n\u001B[1;32m   2357\u001B[0m             loop\u001B[38;5;241m.\u001B[39mtasks\u001B[38;5;241m.\u001B[39mvalues(),\n\u001B[1;32m   2358\u001B[0m             timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_timeout,\n\u001B[1;32m   2359\u001B[0m             retry_policy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry_policy,\n\u001B[1;32m   2360\u001B[0m             get_waiter\u001B[38;5;241m=\u001B[39mget_waiter,\n\u001B[1;32m   2361\u001B[0m         ):\n\u001B[1;32m   2362\u001B[0m             \u001B[38;5;66;03m# emit output\u001B[39;00m\n\u001B[1;32m   2363\u001B[0m             \u001B[38;5;28;01myield from\u001B[39;00m output()\n\u001B[1;32m   2364\u001B[0m \u001B[38;5;66;03m# emit output\u001B[39;00m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/pregel/runner.py:158\u001B[0m, in \u001B[0;36mPregelRunner.tick\u001B[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001B[0m\n\u001B[1;32m    156\u001B[0m t \u001B[38;5;241m=\u001B[39m tasks[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 158\u001B[0m     \u001B[43mrun_with_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfigurable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m            \u001B[49m\u001B[43mCONFIG_KEY_CALL\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m                \u001B[49m\u001B[43m_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m                \u001B[49m\u001B[43mweakref\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m                \u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[43m                \u001B[49m\u001B[43mfutures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweakref\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfutures\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m                \u001B[49m\u001B[43mschedule_task\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mschedule_task\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m                \u001B[49m\u001B[43msubmit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m                \u001B[49m\u001B[43mreraise\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommit(t, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/pregel/retry.py:39\u001B[0m, in \u001B[0;36mrun_with_retry\u001B[0;34m(task, retry_policy, configurable)\u001B[0m\n\u001B[1;32m     37\u001B[0m     task\u001B[38;5;241m.\u001B[39mwrites\u001B[38;5;241m.\u001B[39mclear()\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;66;03m# run the task\u001B[39;00m\n\u001B[0;32m---> 39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ParentCommand \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     41\u001B[0m     ns: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/utils/runnable.py:624\u001B[0m, in \u001B[0;36mRunnableSeq.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    622\u001B[0m                 \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m context\u001B[38;5;241m.\u001B[39mrun(step\u001B[38;5;241m.\u001B[39minvoke, \u001B[38;5;28minput\u001B[39m, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    623\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 624\u001B[0m             \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;66;03m# finish the root run\u001B[39;00m\n\u001B[1;32m    626\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:483\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    479\u001B[0m call_original \u001B[38;5;241m=\u001B[39m update_wrapper_extended(call_original, original)\n\u001B[1;32m    481\u001B[0m event_logger\u001B[38;5;241m.\u001B[39mlog_patch_function_start(args, kwargs)\n\u001B[0;32m--> 483\u001B[0m \u001B[43mpatch_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcall_original\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    485\u001B[0m session\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    486\u001B[0m event_logger\u001B[38;5;241m.\u001B[39mlog_patch_function_success(args, kwargs)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/langchain/_langchain_autolog.py:74\u001B[0m, in \u001B[0;36mpatched_inference\u001B[0;34m(func_name, original, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     72\u001B[0m         _log_optional_artifacts(config, run_id, result, \u001B[38;5;28mself\u001B[39m, func_name, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 74\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_invoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/langchain/_langchain_autolog.py:66\u001B[0m, in \u001B[0;36mpatched_inference.<locals>._invoke\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_invoke\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m disable_patching():\n\u001B[0;32m---> 66\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:474\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001B[0;34m(*og_args, **og_kwargs)\u001B[0m\n\u001B[1;32m    471\u001B[0m         original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n\u001B[1;32m    472\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n\u001B[0;32m--> 474\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall_original_fn_with_event_logging\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_original_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mog_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mog_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:425\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001B[0;34m(original_fn, og_args, og_kwargs)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    423\u001B[0m     event_logger\u001B[38;5;241m.\u001B[39mlog_original_function_start(og_args, og_kwargs)\n\u001B[0;32m--> 425\u001B[0m     original_fn_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mog_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mog_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    427\u001B[0m     event_logger\u001B[38;5;241m.\u001B[39mlog_original_function_success(og_args, og_kwargs)\n\u001B[1;32m    428\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_fn_result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:471\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001B[0;34m(*_og_args, **_og_kwargs)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001B[39;00m\n\u001B[1;32m    464\u001B[0m \u001B[38;5;66;03m# during original function execution, even if silent mode is enabled\u001B[39;00m\n\u001B[1;32m    465\u001B[0m \u001B[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001B[39;00m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001B[39;00m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m NonMlflowWarningsBehaviorForCurrentThread(\n\u001B[1;32m    468\u001B[0m     disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    469\u001B[0m     reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    470\u001B[0m ):\n\u001B[0;32m--> 471\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_og_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_og_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    472\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/utils/runnable.py:376\u001B[0m, in \u001B[0;36mRunnableCallable.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    374\u001B[0m         run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(ret)\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 376\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecurse \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, Runnable):\n\u001B[1;32m    378\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/graph/branch.py:166\u001B[0m, in \u001B[0;36mBranch._route\u001B[0;34m(self, input, config, reader, writer)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    165\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\n\u001B[0;32m--> 166\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_finish(writer, \u001B[38;5;28minput\u001B[39m, result, config)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:483\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    479\u001B[0m call_original \u001B[38;5;241m=\u001B[39m update_wrapper_extended(call_original, original)\n\u001B[1;32m    481\u001B[0m event_logger\u001B[38;5;241m.\u001B[39mlog_patch_function_start(args, kwargs)\n\u001B[0;32m--> 483\u001B[0m \u001B[43mpatch_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcall_original\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    485\u001B[0m session\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    486\u001B[0m event_logger\u001B[38;5;241m.\u001B[39mlog_patch_function_success(args, kwargs)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/langchain/_langchain_autolog.py:74\u001B[0m, in \u001B[0;36mpatched_inference\u001B[0;34m(func_name, original, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     72\u001B[0m         _log_optional_artifacts(config, run_id, result, \u001B[38;5;28mself\u001B[39m, func_name, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 74\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_invoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/langchain/_langchain_autolog.py:66\u001B[0m, in \u001B[0;36mpatched_inference.<locals>._invoke\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_invoke\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m disable_patching():\n\u001B[0;32m---> 66\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:474\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001B[0;34m(*og_args, **og_kwargs)\u001B[0m\n\u001B[1;32m    471\u001B[0m         original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n\u001B[1;32m    472\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n\u001B[0;32m--> 474\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall_original_fn_with_event_logging\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_original_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mog_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mog_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:425\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001B[0;34m(original_fn, og_args, og_kwargs)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    423\u001B[0m     event_logger\u001B[38;5;241m.\u001B[39mlog_original_function_start(og_args, og_kwargs)\n\u001B[0;32m--> 425\u001B[0m     original_fn_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mog_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mog_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    427\u001B[0m     event_logger\u001B[38;5;241m.\u001B[39mlog_original_function_success(og_args, og_kwargs)\n\u001B[1;32m    428\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_fn_result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:471\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001B[0;34m(*_og_args, **_og_kwargs)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001B[39;00m\n\u001B[1;32m    464\u001B[0m \u001B[38;5;66;03m# during original function execution, even if silent mode is enabled\u001B[39;00m\n\u001B[1;32m    465\u001B[0m \u001B[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001B[39;00m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001B[39;00m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m NonMlflowWarningsBehaviorForCurrentThread(\n\u001B[1;32m    468\u001B[0m     disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    469\u001B[0m     reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    470\u001B[0m ):\n\u001B[0;32m--> 471\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_og_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_og_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    472\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/utils/runnable.py:369\u001B[0m, in \u001B[0;36mRunnableCallable.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    367\u001B[0m     \u001B[38;5;66;03m# run in context\u001B[39;00m\n\u001B[1;32m    368\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m set_config_context(child_config, run) \u001B[38;5;28;01mas\u001B[39;00m context:\n\u001B[0;32m--> 369\u001B[0m         ret \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    370\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    371\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "Cell \u001B[0;32mIn[56], line 12\u001B[0m, in \u001B[0;36mroute_to_agent\u001B[0;34m(state)\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpolicy_agent\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 12\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown route: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mroute\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Unknown route: None"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Trace(request_id=70f8e6f48bcf4583abdccd855e8607d4)"
      ],
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=70f8e6f48bcf4583abdccd855e8607d4&amp;experiment_id=328097605715257401&amp;version=2.21.3\"\n",
       "  />\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bd1e1f65c74e31d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

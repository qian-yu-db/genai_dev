{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d46d7393-be29-4029-badc-1388d8d0ea57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# This Notebook is to test the branch tasks of LangGraph\n",
    "\n",
    "The branch tasks are:\n",
    "\n",
    "* A router agent to determine the task\n",
    "* 2 tool calling agents to perform task routed from the router agent\n",
    "* This is chat app instead of a 1 pass tasks"
   ],
   "id": "78e1ebb6502d8048"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8b302aa-1601-4224-a178-06e82800ccda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt --quiet\n",
    "%restart_python"
   ],
   "id": "12efc1d4a5a84293"
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31f7ee5b-1773-421c-a106-1daa92ea06c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-04-24T19:25:06.677693Z",
     "start_time": "2025-04-24T19:25:05.756093Z"
    }
   },
   "source": [
    "local = True\n",
    "\n",
    "if local:\n",
    "    from databricks.connect import DatabricksSession\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "\n",
    "    spark = DatabricksSession.builder.getOrCreate()\n",
    "    load_dotenv('../.env')\n",
    "\n",
    "    DATABRICKS_HOST = os.getenv('host')\n",
    "    DATABRICKS_TOKEN = os.getenv('token')\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "else:\n",
    "    DATABRICKS_HOST = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().get()\n",
    "    OPENAI_API_KEY = dbutils.secrets.get(\"databricks_token_qyu\", \"OpenAi\")\n",
    "\n",
    "print(f\"host: {DATABRICKS_HOST}\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "773fce5902d943bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host: adb-984752964297111.11.azuredatabricks.net\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a98214fa-9d3c-4e44-8c9f-bb6f245d7ce5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-04-24T19:25:06.703161Z",
     "start_time": "2025-04-24T19:25:06.683403Z"
    }
   },
   "source": [
    "from unitycatalog.ai.core.base import set_uc_function_client\n",
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient\n",
    "\n",
    "client = DatabricksFunctionClient()\n",
    "set_uc_function_client(client)\n",
    "\n",
    "CATALOG = 'dhuang'\n",
    "SCHEMA = 'insurance_agent'"
   ],
   "id": "59568a7877a4cb5e",
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b579986-f262-44ce-a736-ca2d948bc5c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-04-24T19:25:07.259202Z",
     "start_time": "2025-04-24T19:25:07.081326Z"
    }
   },
   "source": [
    "from typing import Any, Generator, Optional, Sequence, Union, TypedDict, Dict, List\n",
    "from typing_extensions import Literal\n",
    "\n",
    "import mlflow\n",
    "from pydantic import BaseModel, Field\n",
    "from databricks_langchain import ChatDatabricks, VectorSearchRetrieverTool\n",
    "from databricks_langchain.uc_ai import (\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage\n",
    "from langchain_core.tools import BaseTool\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "\n",
    "if local:\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_registry_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"langgraph_test\")\n",
    "else:\n",
    "    mlflow.set_tracking_uri(\"databricks\")\n",
    "    mlflow.set_registry_uri(\"databricks-uc\")\n",
    "    mlflow.set_experiment(\"/Users/q.yu@databricks.com/ML_experiments/insurance_chat_agents\")\n",
    "\n",
    "mlflow.langchain.autolog()"
   ],
   "id": "5b2519e4ab9be344",
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60061f62-f019-48f4-aff0-783d69663241",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-04-24T20:53:56.986921Z",
     "start_time": "2025-04-24T20:53:56.816856Z"
    }
   },
   "source": [
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-3-7-sonnet\"\n",
    "LLM = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "RECOMMENDED_PROMPT_PREFIX = \"\"\"\n",
    "    # System context\n",
    "    You are part of a multi-agent system, designed to make agent coordination and execution easy.\n",
    "    Agents uses two primary abstraction: **Agents** and **Handoffs**.\n",
    "    An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate.\n",
    "    Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`.\n",
    "    Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\n",
    "\"\"\"\n",
    "\n",
    "TRIAGE_PROMPT = \"\"\"\n",
    "    You are a helpful triaging agent.\n",
    "    You analyze the customer's questions and classify questions to other appropriate agents.\n",
    "    - if the question is related to claims, classify it to the \"claim detail retrieval\"\n",
    "    - if the question is related to policy questions, classify it to the \"policy questions\"\n",
    "    - if the question is not related to either, ask the customer to clarify their question.\n",
    "    - if the customer does not have anymore questions, wish them a goodbye and a good rest of their day.\n",
    "\"\"\"\n",
    "\n",
    "CLAIMS_DETAIL_RETRIEVAL_PROMPT = \"\"\"\n",
    "    You are a claims details retrieval agent.\n",
    "    If you are speaking to a customer, you probably were transferred to you from the triage agent.\n",
    "    Use the following routine to support the customer.\n",
    "    # Routine:\n",
    "    1. Identify the last question asked by the customer.\n",
    "    2. Use the search tools to retrieve data about a claim. Do not rely on your own knowledge.\n",
    "    3. If you cannot answer the question, transfer back to the triage agent.\n",
    "\"\"\"\n",
    "\n",
    "POLICY_QA_AGENT_PROMPT = \"\"\"\n",
    "    You are an insurance policy Q&A agent.\n",
    "    If you are speaking to a customer, you probably were transferred to you from the triage agent.\n",
    "    Use the following routine to support the customer.\n",
    "    # Routine:\n",
    "    1. Identify the last question asked by the customer.\n",
    "    2. Use the search tools to answer the question about their policy. Do not rely on your own knowledge.\n",
    "    3. If you cannot answer the question, transfer back to the triage agent.\n",
    "\"\"\""
   ],
   "id": "3a061fa1e201f639",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b3/rdsklr3d0s1f_fzq3pg5try40000gp/T/ipykernel_73216/2748924824.py:5: DeprecationWarning: Currently, temperature defaults to 0.0 if not specified. In the next release, temperature will need to be explicitly set. Please update your code to specify a temperature value. Note: If you are using an o1 or o3 model, you need to set temperature=None.\n",
      "  LLM = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f89122d6-fb9f-4b64-bd12-fb3e125a2743",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create a Tool Calling Agent function"
   ],
   "id": "b091a4cd685765c7"
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55865fd8-db58-4108-aaa2-3b4824fd8f46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-04-24T20:53:58.056963Z",
     "start_time": "2025-04-24T20:53:58.035523Z"
    }
   },
   "source": [
    "def create_tool_calling_agent(model: LanguageModelLike,\n",
    "                              tools: Union[ToolNode, Sequence[BaseTool]],\n",
    "                              system_prompt: Optional[str] = None,\n",
    "                              ) -> CompiledGraph:\n",
    "    \"\"\"Creates an agent for handling claim detail retrieval requests.\"\"\"\n",
    "\n",
    "    # Bind tools to the model\n",
    "    model = model.bind_tools(tools)\n",
    "\n",
    "    # Define the function that determines which node to go to\n",
    "    def should_continue(state: ChatAgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        last_message = messages[-1]\n",
    "        # If there are function calls, continue. else, end\n",
    "        if last_message.get(\"tool_calls\"):\n",
    "            return \"continue\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "\n",
    "    # Create the message preprocessor with system prompt\n",
    "    if system_prompt:\n",
    "        preprocessor = RunnableLambda(\n",
    "            lambda state: [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "                          + state[\"messages\"]\n",
    "        )\n",
    "    else:\n",
    "        preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "    model_runnable = preprocessor | model\n",
    "\n",
    "    # Define the call_model function\n",
    "    def call_model(\n",
    "            state: ChatAgentState,\n",
    "            config: RunnableConfig\n",
    "    ):\n",
    "        response = model_runnable.invoke(state, config)\n",
    "\n",
    "        # set route back to unknown with tool-calling agents\n",
    "        custom_outputs = state.get('custom_outputs', {}).copy()\n",
    "        custom_outputs['route'] = \"unknown\"\n",
    "\n",
    "        return {\"messages\": state[\"messages\"] + [response], \"custom_outputs\": custom_outputs}\n",
    "\n",
    "    # Create the workflow graph\n",
    "    workflow = StateGraph(ChatAgentState)\n",
    "    workflow.add_node(\"agent\", RunnableLambda(call_model))\n",
    "    workflow.add_node(\"tools\", ChatAgentToolNode(tools))\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"continue\": \"tools\",\n",
    "            \"end\": END,\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "    return workflow.compile()\n"
   ],
   "id": "6583cca8fabaf5fa",
   "outputs": [],
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "587e099f-8a30-4cc9-add4-4e1635f0dda2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create a Triage Agent (Rounter) Function"
   ],
   "id": "8f698481954942c7"
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df4fd965-a6a4-4af4-afb2-e4edf2def4c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-04-24T20:53:58.954998Z",
     "start_time": "2025-04-24T20:53:58.934503Z"
    }
   },
   "source": [
    "def create_triage_agent(model: LanguageModelLike,\n",
    "                        system_prompt: Optional[str] = None,\n",
    "                        ) -> RunnableLambda:\n",
    "    \"\"\"Create a triage agent to route the input to the appropriate tool agent\"\"\"\n",
    "\n",
    "    def triage_query(state: ChatAgentState, config: RunnableConfig):\n",
    "        user_messages = [msg for msg in state['messages'] if msg.get(\"role\") == \"user\"]\n",
    "\n",
    "        if not user_messages:\n",
    "            return {\"route\": \"need clarification\"}\n",
    "\n",
    "        latest_user_msg = user_messages[-1]\n",
    "        user_query = latest_user_msg.get(\"content\", \"\")\n",
    "\n",
    "        # Prepare classification request\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"customer question: {user_query}\"}\n",
    "        ]\n",
    "        custom_outputs = state.get('custom_outputs', {}).copy()\n",
    "\n",
    "        # Get classification from the model\n",
    "        response = model.invoke(messages)\n",
    "        classification = response.content.strip().lower()\n",
    "        print(f\"[debug] classification is {classification}\")\n",
    "\n",
    "        # Determine routing based on classification\n",
    "        if \"claim detail retrieval\" in classification:\n",
    "            print(\"[DEBUG] route to claim agent\")\n",
    "            custom_outputs['route'] = \"claim_detail_retrieval\"\n",
    "            return {\"messages\": messages, \"custom_outputs\": custom_outputs}\n",
    "        elif \"policy question\" in classification:\n",
    "            print(\"[DEBUG] route to policy agent\")\n",
    "            custom_outputs['route'] = \"policy_questions\"\n",
    "            return {\"messages\": messages, \"custom_outputs\": custom_outputs}\n",
    "        else:\n",
    "            print(\"[DEBUG] route back to triage agent\")\n",
    "            custom_outputs['route'] = \"unknown\"\n",
    "            return {\"messages\": messages, \"custom_outputs\": custom_outputs}\n",
    "\n",
    "    return RunnableLambda(triage_query)"
   ],
   "id": "5df576b35f1313d2",
   "outputs": [],
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea5f738c-4110-4867-af50-7ecbf5564407",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create multi-agent workflow"
   ],
   "id": "7dfa6b342be0bebb"
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d67e77b-2e5d-42be-99c7-fedab288ae10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-04-24T20:54:00.695008Z",
     "start_time": "2025-04-24T20:54:00.454075Z"
    }
   },
   "source": [
    "uc_tool_name = [f\"{CATALOG}.{SCHEMA}.{func.name}\" for func in client.list_functions(catalog=CATALOG,\n",
    "                                                                                    schema=SCHEMA)]\n",
    "selected_uc_tool_names = uc_tool_name[:2]\n",
    "print(selected_uc_tool_names)"
   ],
   "id": "c37ba24ac7575e4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dhuang.insurance_agent.policy_docs_vector_search', 'dhuang.insurance_agent.search_claims_details_by_policy_no']\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d7d0853-e4e3-4663-ae69-411526d728df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-04-24T20:54:01.714736Z",
     "start_time": "2025-04-24T20:54:01.394162Z"
    }
   },
   "source": [
    "tools = []\n",
    "uc_toolkit = UCFunctionToolkit(function_names=selected_uc_tool_names)\n",
    "tools.extend(uc_toolkit.tools)"
   ],
   "id": "de33859b4df80d3e",
   "outputs": [],
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c92a9a10-05a3-4e2f-829b-44994a5deada",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-04-24T20:54:56.576159Z",
     "start_time": "2025-04-24T20:54:56.446168Z"
    }
   },
   "source": [
    "triage_agent = create_triage_agent(LLM, TRIAGE_PROMPT)\n",
    "claim_agent = create_tool_calling_agent(LLM, [tools[1]], CLAIMS_DETAIL_RETRIEVAL_PROMPT)\n",
    "policy_agent = create_tool_calling_agent(LLM, [tools[0]], POLICY_QA_AGENT_PROMPT)\n",
    "\n",
    "def route_to_agent(state: ChatAgentState):\n",
    "    route = state['custom_outputs']['route']\n",
    "    if route == \"claim_detail_retrieval\":\n",
    "        print(\"[DEBUG] route to claim_agent\")\n",
    "        return \"claim_agent\"\n",
    "    elif route == \"policy_questions\":\n",
    "        print(\"[DEBUG] route to policy_agent\")\n",
    "        return \"policy_agent\"\n",
    "    elif route == 'unknown':\n",
    "        print(\"[DEBUG] route to triage_agent\")\n",
    "        return \"triage_agent\"\n",
    "    else:\n",
    "        print(\"[DEBUG] route to triage_agent\")\n",
    "        return \"triage_agent\""
   ],
   "id": "cb63cdf6e6be004e",
   "outputs": [],
   "execution_count": 108
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63553f4a-8163-4fe6-99e0-0e21980c6da0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create the multi-agent workflow"
   ],
   "id": "19c5e658385afb3"
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5141ae61-82a3-4d13-9286-eb04f84de5ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-04-24T20:54:57.435589Z",
     "start_time": "2025-04-24T20:54:57.414154Z"
    }
   },
   "source": [
    "workflow = StateGraph(ChatAgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"triage_agent\", triage_agent)\n",
    "workflow.add_node(\"claim_agent\", claim_agent)\n",
    "workflow.add_node(\"policy_agent\", policy_agent)\n",
    "\n",
    "# Add edges\n",
    "workflow.set_entry_point(\"triage_agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"triage_agent\",\n",
    "    route_to_agent,\n",
    "    {\n",
    "        \"claim_agent\": \"claim_agent\",\n",
    "        \"policy_agent\": \"policy_agent\",\n",
    "        \"triage_agent\": \"triage_agent\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"claim_agent\", END)\n",
    "workflow.add_edge(\"policy_agent\", END)\n",
    "\n",
    "# Shall I add these edges to return to the triage agent for new questions?\n",
    "# workflow.add_edge(\"claim_agent\", \"triage_agent\")\n",
    "# workflow.add_edge(\"policy_agent\", \"triage_agent\")\n",
    "\n",
    "insurance_agent_workflow = workflow.compile()"
   ],
   "id": "54cb9d182cfa708d",
   "outputs": [],
   "execution_count": 109
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17de1947-4095-43e3-be43-4f8526d81c9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-04-24T20:54:58.082363Z",
     "start_time": "2025-04-24T20:54:57.910815Z"
    }
   },
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(insurance_agent_workflow.get_graph().draw_mermaid_png()))"
   ],
   "id": "9c1d00455e3590e",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 110
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6271831b-01fd-404f-8cf6-8aba15223d14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create ChatAgent Model"
   ],
   "id": "bd0088927a4563ca"
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f84b577-d29c-4319-a100-b706968665ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-04-24T20:54:59.436723Z",
     "start_time": "2025-04-24T20:54:59.418157Z"
    }
   },
   "source": [
    "class InsuranceMultiAgentChatAgent(ChatAgent):\n",
    "    \"\"\"MLflow ChatAgent implementation for the insurance multi-agent workflow.\"\"\"\n",
    "\n",
    "    def __init__(self, agent: CompiledGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: List[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[Dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        \"\"\"Processes a conversation and returns a response.\"\"\"\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        # Execute the workflow\n",
    "        result = self.agent.invoke(request)\n",
    "\n",
    "        # Convert messages to ChatAgentMessage format\n",
    "        response_messages = []\n",
    "        for node_name, node_data in result.items():\n",
    "            if isinstance(node_data, dict) and \"messages\" in node_data:\n",
    "                for msg in node_data[\"messages\"]:\n",
    "                    if isinstance(msg, dict):\n",
    "                        response_messages.append(ChatAgentMessage(**msg))\n",
    "\n",
    "        return ChatAgentResponse(messages=response_messages)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: List[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[Dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        \"\"\"Streams the agent's response.\"\"\"\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        # Stream the workflow execution\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                if isinstance(node_data, dict) and \"messages\" in node_data:\n",
    "                    for msg in node_data[\"messages\"]:\n",
    "                        if isinstance(msg, dict):\n",
    "                            yield ChatAgentChunk(delta=msg)\n"
   ],
   "id": "a7266c32b88a63c9",
   "outputs": [],
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cac44f7e-eab7-45a7-bbd3-6f668c9d6931",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-04-24T20:55:02.814031Z",
     "start_time": "2025-04-24T20:55:02.786071Z"
    }
   },
   "source": [
    "AGENT = InsuranceMultiAgentChatAgent(insurance_agent_workflow)\n",
    "mlflow.models.set_model(AGENT)"
   ],
   "id": "e37decbc8263f38d",
   "outputs": [],
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0947cb04-0a4a-4a10-85ea-c4108144a968",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-04-24T20:55:20.192446Z",
     "start_time": "2025-04-24T20:55:03.434680Z"
    }
   },
   "source": "result = AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"hi, id like to check on my existing claims and my policy number: 102070455\"}]})",
   "id": "63b172036a16ca90",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] classification is i'll help you with that. based on your question, i'll classify this to the \"claim detail retrieval\" agent since you're asking about checking on your existing claims. you've also provided your policy number (102070455), which will be helpful for retrieving your claim information.\n",
      "\n",
      "is there anything specific about your claims that you'd like to know?\n",
      "[DEBUG] route to claim agent\n",
      "[DEBUG] route to claim_agent\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[113], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mAGENT\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhi, id like to check on my existing claims and my policy number: 102070455\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/pyfunc/utils/data_validation.py:119\u001B[0m, in \u001B[0;36mwrap_non_list_predict_pydantic.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    117\u001B[0m     param_names \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39msignature(func)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mkeys() \u001B[38;5;241m-\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m    118\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m {k: \u001B[38;5;28mgetattr\u001B[39m(pydantic_obj, k) \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m param_names}\n\u001B[0;32m--> 119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, pydantic_obj)\n",
      "Cell \u001B[0;32mIn[111], line 17\u001B[0m, in \u001B[0;36mInsuranceMultiAgentChatAgent.predict\u001B[0;34m(self, messages, context, custom_inputs)\u001B[0m\n\u001B[1;32m     14\u001B[0m request \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_messages_to_dict(messages)}\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Execute the workflow\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Convert messages to ChatAgentMessage format\u001B[39;00m\n\u001B[1;32m     20\u001B[0m response_messages \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:483\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    479\u001B[0m call_original \u001B[38;5;241m=\u001B[39m update_wrapper_extended(call_original, original)\n\u001B[1;32m    481\u001B[0m event_logger\u001B[38;5;241m.\u001B[39mlog_patch_function_start(args, kwargs)\n\u001B[0;32m--> 483\u001B[0m \u001B[43mpatch_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcall_original\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    485\u001B[0m session\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    486\u001B[0m event_logger\u001B[38;5;241m.\u001B[39mlog_patch_function_success(args, kwargs)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/langchain/_langchain_autolog.py:74\u001B[0m, in \u001B[0;36mpatched_inference\u001B[0;34m(func_name, original, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     72\u001B[0m         _log_optional_artifacts(config, run_id, result, \u001B[38;5;28mself\u001B[39m, func_name, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 74\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_invoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/langchain/_langchain_autolog.py:66\u001B[0m, in \u001B[0;36mpatched_inference.<locals>._invoke\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_invoke\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m disable_patching():\n\u001B[0;32m---> 66\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:474\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001B[0;34m(*og_args, **og_kwargs)\u001B[0m\n\u001B[1;32m    471\u001B[0m         original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n\u001B[1;32m    472\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n\u001B[0;32m--> 474\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall_original_fn_with_event_logging\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_original_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mog_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mog_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:425\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001B[0;34m(original_fn, og_args, og_kwargs)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    423\u001B[0m     event_logger\u001B[38;5;241m.\u001B[39mlog_original_function_start(og_args, og_kwargs)\n\u001B[0;32m--> 425\u001B[0m     original_fn_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mog_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mog_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    427\u001B[0m     event_logger\u001B[38;5;241m.\u001B[39mlog_original_function_success(og_args, og_kwargs)\n\u001B[1;32m    428\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_fn_result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:471\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001B[0;34m(*_og_args, **_og_kwargs)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001B[39;00m\n\u001B[1;32m    464\u001B[0m \u001B[38;5;66;03m# during original function execution, even if silent mode is enabled\u001B[39;00m\n\u001B[1;32m    465\u001B[0m \u001B[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001B[39;00m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001B[39;00m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m NonMlflowWarningsBehaviorForCurrentThread(\n\u001B[1;32m    468\u001B[0m     disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    469\u001B[0m     reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    470\u001B[0m ):\n\u001B[0;32m--> 471\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_og_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_og_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    472\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2718\u001B[0m, in \u001B[0;36mPregel.invoke\u001B[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001B[0m\n\u001B[1;32m   2716\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2717\u001B[0m     chunks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m-> 2718\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream(\n\u001B[1;32m   2719\u001B[0m     \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   2720\u001B[0m     config,\n\u001B[1;32m   2721\u001B[0m     stream_mode\u001B[38;5;241m=\u001B[39mstream_mode,\n\u001B[1;32m   2722\u001B[0m     output_keys\u001B[38;5;241m=\u001B[39moutput_keys,\n\u001B[1;32m   2723\u001B[0m     interrupt_before\u001B[38;5;241m=\u001B[39minterrupt_before,\n\u001B[1;32m   2724\u001B[0m     interrupt_after\u001B[38;5;241m=\u001B[39minterrupt_after,\n\u001B[1;32m   2725\u001B[0m     checkpoint_during\u001B[38;5;241m=\u001B[39mcheckpoint_during,\n\u001B[1;32m   2726\u001B[0m     debug\u001B[38;5;241m=\u001B[39mdebug,\n\u001B[1;32m   2727\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   2728\u001B[0m ):\n\u001B[1;32m   2729\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   2730\u001B[0m         latest \u001B[38;5;241m=\u001B[39m chunk\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2356\u001B[0m, in \u001B[0;36mPregel.stream\u001B[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001B[0m\n\u001B[1;32m   2350\u001B[0m     \u001B[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001B[39;00m\n\u001B[1;32m   2351\u001B[0m     \u001B[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001B[39;00m\n\u001B[1;32m   2352\u001B[0m     \u001B[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001B[39;00m\n\u001B[1;32m   2353\u001B[0m     \u001B[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001B[39;00m\n\u001B[1;32m   2354\u001B[0m     \u001B[38;5;66;03m# with channel updates applied only at the transition between steps.\u001B[39;00m\n\u001B[1;32m   2355\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m loop\u001B[38;5;241m.\u001B[39mtick(input_keys\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_channels):\n\u001B[0;32m-> 2356\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m runner\u001B[38;5;241m.\u001B[39mtick(\n\u001B[1;32m   2357\u001B[0m             loop\u001B[38;5;241m.\u001B[39mtasks\u001B[38;5;241m.\u001B[39mvalues(),\n\u001B[1;32m   2358\u001B[0m             timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_timeout,\n\u001B[1;32m   2359\u001B[0m             retry_policy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry_policy,\n\u001B[1;32m   2360\u001B[0m             get_waiter\u001B[38;5;241m=\u001B[39mget_waiter,\n\u001B[1;32m   2361\u001B[0m         ):\n\u001B[1;32m   2362\u001B[0m             \u001B[38;5;66;03m# emit output\u001B[39;00m\n\u001B[1;32m   2363\u001B[0m             \u001B[38;5;28;01myield from\u001B[39;00m output()\n\u001B[1;32m   2364\u001B[0m \u001B[38;5;66;03m# emit output\u001B[39;00m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/pregel/runner.py:158\u001B[0m, in \u001B[0;36mPregelRunner.tick\u001B[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001B[0m\n\u001B[1;32m    156\u001B[0m t \u001B[38;5;241m=\u001B[39m tasks[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 158\u001B[0m     \u001B[43mrun_with_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfigurable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m            \u001B[49m\u001B[43mCONFIG_KEY_CALL\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m                \u001B[49m\u001B[43m_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m                \u001B[49m\u001B[43mweakref\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m                \u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[43m                \u001B[49m\u001B[43mfutures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweakref\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfutures\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m                \u001B[49m\u001B[43mschedule_task\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mschedule_task\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m                \u001B[49m\u001B[43msubmit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m                \u001B[49m\u001B[43mreraise\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommit(t, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/pregel/retry.py:39\u001B[0m, in \u001B[0;36mrun_with_retry\u001B[0;34m(task, retry_policy, configurable)\u001B[0m\n\u001B[1;32m     37\u001B[0m     task\u001B[38;5;241m.\u001B[39mwrites\u001B[38;5;241m.\u001B[39mclear()\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;66;03m# run the task\u001B[39;00m\n\u001B[0;32m---> 39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ParentCommand \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     41\u001B[0m     ns: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/utils/runnable.py:622\u001B[0m, in \u001B[0;36mRunnableSeq.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    620\u001B[0m     \u001B[38;5;66;03m# run in context\u001B[39;00m\n\u001B[1;32m    621\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m set_config_context(config, run) \u001B[38;5;28;01mas\u001B[39;00m context:\n\u001B[0;32m--> 622\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    623\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    624\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:483\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    479\u001B[0m call_original \u001B[38;5;241m=\u001B[39m update_wrapper_extended(call_original, original)\n\u001B[1;32m    481\u001B[0m event_logger\u001B[38;5;241m.\u001B[39mlog_patch_function_start(args, kwargs)\n\u001B[0;32m--> 483\u001B[0m \u001B[43mpatch_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcall_original\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    485\u001B[0m session\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    486\u001B[0m event_logger\u001B[38;5;241m.\u001B[39mlog_patch_function_success(args, kwargs)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/langchain/_langchain_autolog.py:74\u001B[0m, in \u001B[0;36mpatched_inference\u001B[0;34m(func_name, original, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     72\u001B[0m         _log_optional_artifacts(config, run_id, result, \u001B[38;5;28mself\u001B[39m, func_name, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 74\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_invoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/langchain/_langchain_autolog.py:66\u001B[0m, in \u001B[0;36mpatched_inference.<locals>._invoke\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_invoke\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m disable_patching():\n\u001B[0;32m---> 66\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:474\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001B[0;34m(*og_args, **og_kwargs)\u001B[0m\n\u001B[1;32m    471\u001B[0m         original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n\u001B[1;32m    472\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n\u001B[0;32m--> 474\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall_original_fn_with_event_logging\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_original_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mog_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mog_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:425\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001B[0;34m(original_fn, og_args, og_kwargs)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    423\u001B[0m     event_logger\u001B[38;5;241m.\u001B[39mlog_original_function_start(og_args, og_kwargs)\n\u001B[0;32m--> 425\u001B[0m     original_fn_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mog_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mog_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    427\u001B[0m     event_logger\u001B[38;5;241m.\u001B[39mlog_original_function_success(og_args, og_kwargs)\n\u001B[1;32m    428\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_fn_result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:471\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001B[0;34m(*_og_args, **_og_kwargs)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001B[39;00m\n\u001B[1;32m    464\u001B[0m \u001B[38;5;66;03m# during original function execution, even if silent mode is enabled\u001B[39;00m\n\u001B[1;32m    465\u001B[0m \u001B[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001B[39;00m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001B[39;00m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m NonMlflowWarningsBehaviorForCurrentThread(\n\u001B[1;32m    468\u001B[0m     disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    469\u001B[0m     reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    470\u001B[0m ):\n\u001B[0;32m--> 471\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_og_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_og_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    472\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2718\u001B[0m, in \u001B[0;36mPregel.invoke\u001B[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001B[0m\n\u001B[1;32m   2716\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2717\u001B[0m     chunks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m-> 2718\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream(\n\u001B[1;32m   2719\u001B[0m     \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   2720\u001B[0m     config,\n\u001B[1;32m   2721\u001B[0m     stream_mode\u001B[38;5;241m=\u001B[39mstream_mode,\n\u001B[1;32m   2722\u001B[0m     output_keys\u001B[38;5;241m=\u001B[39moutput_keys,\n\u001B[1;32m   2723\u001B[0m     interrupt_before\u001B[38;5;241m=\u001B[39minterrupt_before,\n\u001B[1;32m   2724\u001B[0m     interrupt_after\u001B[38;5;241m=\u001B[39minterrupt_after,\n\u001B[1;32m   2725\u001B[0m     checkpoint_during\u001B[38;5;241m=\u001B[39mcheckpoint_during,\n\u001B[1;32m   2726\u001B[0m     debug\u001B[38;5;241m=\u001B[39mdebug,\n\u001B[1;32m   2727\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   2728\u001B[0m ):\n\u001B[1;32m   2729\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   2730\u001B[0m         latest \u001B[38;5;241m=\u001B[39m chunk\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2356\u001B[0m, in \u001B[0;36mPregel.stream\u001B[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001B[0m\n\u001B[1;32m   2350\u001B[0m     \u001B[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001B[39;00m\n\u001B[1;32m   2351\u001B[0m     \u001B[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001B[39;00m\n\u001B[1;32m   2352\u001B[0m     \u001B[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001B[39;00m\n\u001B[1;32m   2353\u001B[0m     \u001B[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001B[39;00m\n\u001B[1;32m   2354\u001B[0m     \u001B[38;5;66;03m# with channel updates applied only at the transition between steps.\u001B[39;00m\n\u001B[1;32m   2355\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m loop\u001B[38;5;241m.\u001B[39mtick(input_keys\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_channels):\n\u001B[0;32m-> 2356\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m runner\u001B[38;5;241m.\u001B[39mtick(\n\u001B[1;32m   2357\u001B[0m             loop\u001B[38;5;241m.\u001B[39mtasks\u001B[38;5;241m.\u001B[39mvalues(),\n\u001B[1;32m   2358\u001B[0m             timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_timeout,\n\u001B[1;32m   2359\u001B[0m             retry_policy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry_policy,\n\u001B[1;32m   2360\u001B[0m             get_waiter\u001B[38;5;241m=\u001B[39mget_waiter,\n\u001B[1;32m   2361\u001B[0m         ):\n\u001B[1;32m   2362\u001B[0m             \u001B[38;5;66;03m# emit output\u001B[39;00m\n\u001B[1;32m   2363\u001B[0m             \u001B[38;5;28;01myield from\u001B[39;00m output()\n\u001B[1;32m   2364\u001B[0m \u001B[38;5;66;03m# emit output\u001B[39;00m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/pregel/runner.py:158\u001B[0m, in \u001B[0;36mPregelRunner.tick\u001B[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001B[0m\n\u001B[1;32m    156\u001B[0m t \u001B[38;5;241m=\u001B[39m tasks[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 158\u001B[0m     \u001B[43mrun_with_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfigurable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m            \u001B[49m\u001B[43mCONFIG_KEY_CALL\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m                \u001B[49m\u001B[43m_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m                \u001B[49m\u001B[43mweakref\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m                \u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[43m                \u001B[49m\u001B[43mfutures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweakref\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfutures\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m                \u001B[49m\u001B[43mschedule_task\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mschedule_task\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m                \u001B[49m\u001B[43msubmit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m                \u001B[49m\u001B[43mreraise\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommit(t, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/pregel/retry.py:39\u001B[0m, in \u001B[0;36mrun_with_retry\u001B[0;34m(task, retry_policy, configurable)\u001B[0m\n\u001B[1;32m     37\u001B[0m     task\u001B[38;5;241m.\u001B[39mwrites\u001B[38;5;241m.\u001B[39mclear()\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;66;03m# run the task\u001B[39;00m\n\u001B[0;32m---> 39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ParentCommand \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     41\u001B[0m     ns: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langgraph/utils/runnable.py:622\u001B[0m, in \u001B[0;36mRunnableSeq.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    620\u001B[0m     \u001B[38;5;66;03m# run in context\u001B[39;00m\n\u001B[1;32m    621\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m set_config_context(config, run) \u001B[38;5;28;01mas\u001B[39;00m context:\n\u001B[0;32m--> 622\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    623\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    624\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:483\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    479\u001B[0m call_original \u001B[38;5;241m=\u001B[39m update_wrapper_extended(call_original, original)\n\u001B[1;32m    481\u001B[0m event_logger\u001B[38;5;241m.\u001B[39mlog_patch_function_start(args, kwargs)\n\u001B[0;32m--> 483\u001B[0m \u001B[43mpatch_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcall_original\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    485\u001B[0m session\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    486\u001B[0m event_logger\u001B[38;5;241m.\u001B[39mlog_patch_function_success(args, kwargs)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/langchain/_langchain_autolog.py:74\u001B[0m, in \u001B[0;36mpatched_inference\u001B[0;34m(func_name, original, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     72\u001B[0m         _log_optional_artifacts(config, run_id, result, \u001B[38;5;28mself\u001B[39m, func_name, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 74\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_invoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/langchain/_langchain_autolog.py:66\u001B[0m, in \u001B[0;36mpatched_inference.<locals>._invoke\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_invoke\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m disable_patching():\n\u001B[0;32m---> 66\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:474\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001B[0;34m(*og_args, **og_kwargs)\u001B[0m\n\u001B[1;32m    471\u001B[0m         original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n\u001B[1;32m    472\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n\u001B[0;32m--> 474\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall_original_fn_with_event_logging\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_original_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mog_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mog_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:425\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001B[0;34m(original_fn, og_args, og_kwargs)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    423\u001B[0m     event_logger\u001B[38;5;241m.\u001B[39mlog_original_function_start(og_args, og_kwargs)\n\u001B[0;32m--> 425\u001B[0m     original_fn_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mog_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mog_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    427\u001B[0m     event_logger\u001B[38;5;241m.\u001B[39mlog_original_function_success(og_args, og_kwargs)\n\u001B[1;32m    428\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_fn_result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:471\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001B[0;34m(*_og_args, **_og_kwargs)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001B[39;00m\n\u001B[1;32m    464\u001B[0m \u001B[38;5;66;03m# during original function execution, even if silent mode is enabled\u001B[39;00m\n\u001B[1;32m    465\u001B[0m \u001B[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001B[39;00m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001B[39;00m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m NonMlflowWarningsBehaviorForCurrentThread(\n\u001B[1;32m    468\u001B[0m     disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    469\u001B[0m     reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    470\u001B[0m ):\n\u001B[0;32m--> 471\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m \u001B[43moriginal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_og_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_og_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    472\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:4757\u001B[0m, in \u001B[0;36mRunnableLambda.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   4743\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001B[39;00m\n\u001B[1;32m   4744\u001B[0m \n\u001B[1;32m   4745\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4754\u001B[0m \u001B[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001B[39;00m\n\u001B[1;32m   4755\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4756\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunc\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 4757\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_with_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4758\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_invoke\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4759\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4760\u001B[0m \u001B[43m        \u001B[49m\u001B[43mensure_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4761\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4762\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4763\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4764\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1930\u001B[0m, in \u001B[0;36mRunnable._call_with_config\u001B[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001B[0m\n\u001B[1;32m   1926\u001B[0m     child_config \u001B[38;5;241m=\u001B[39m patch_config(config, callbacks\u001B[38;5;241m=\u001B[39mrun_manager\u001B[38;5;241m.\u001B[39mget_child())\n\u001B[1;32m   1927\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m set_config_context(child_config) \u001B[38;5;28;01mas\u001B[39;00m context:\n\u001B[1;32m   1928\u001B[0m         output \u001B[38;5;241m=\u001B[39m cast(\n\u001B[1;32m   1929\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOutput\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m-> 1930\u001B[0m             \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1931\u001B[0m \u001B[43m                \u001B[49m\u001B[43mcall_func_with_variable_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1932\u001B[0m \u001B[43m                \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1933\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1934\u001B[0m \u001B[43m                \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1935\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1936\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1937\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   1938\u001B[0m         )\n\u001B[1;32m   1939\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1940\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langchain_core/runnables/config.py:428\u001B[0m, in \u001B[0;36mcall_func_with_variable_args\u001B[0;34m(func, input, config, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m accepts_run_manager(func):\n\u001B[1;32m    427\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m run_manager\n\u001B[0;32m--> 428\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:4615\u001B[0m, in \u001B[0;36mRunnableLambda._invoke\u001B[0;34m(self, input, run_manager, config, **kwargs)\u001B[0m\n\u001B[1;32m   4613\u001B[0m                 output \u001B[38;5;241m=\u001B[39m chunk\n\u001B[1;32m   4614\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 4615\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mcall_func_with_variable_args\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4616\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m   4617\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4618\u001B[0m \u001B[38;5;66;03m# If the output is a Runnable, invoke it\u001B[39;00m\n\u001B[1;32m   4619\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, Runnable):\n",
      "File \u001B[0;32m~/workspace/genai_dev/.venv/lib/python3.10/site-packages/langchain_core/runnables/config.py:428\u001B[0m, in \u001B[0;36mcall_func_with_variable_args\u001B[0;34m(func, input, config, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m accepts_run_manager(func):\n\u001B[1;32m    427\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m run_manager\n\u001B[0;32m--> 428\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[98], line 38\u001B[0m, in \u001B[0;36mcreate_tool_calling_agent.<locals>.call_model\u001B[0;34m(state, config)\u001B[0m\n\u001B[1;32m     35\u001B[0m response \u001B[38;5;241m=\u001B[39m model_runnable\u001B[38;5;241m.\u001B[39minvoke(state, config)\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# set route back to unknown with tool-calling agents\u001B[39;00m\n\u001B[0;32m---> 38\u001B[0m custom_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcustom_outputs\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m()\n\u001B[1;32m     39\u001B[0m custom_outputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mroute\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munknown\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m [response], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcustom_outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: custom_outputs}\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'copy'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Trace(request_id=55a9cfb8e09945daba8760335c0ff9a5)"
      ],
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=55a9cfb8e09945daba8760335c0ff9a5&amp;experiment_id=328097605715257401&amp;version=2.21.3\"\n",
       "  />\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a871d206-e088-4e69-9e2b-771bc69df26d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "ExecuteTime": {
     "end_time": "2025-04-24T20:37:13.598797Z",
     "start_time": "2025-04-24T20:37:13.576452Z"
    }
   },
   "source": "result",
   "id": "b0f3ddc7aa78471b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatAgentResponse(messages=[], finish_reason=None, custom_outputs=None, usage=None)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "265edf072464c02b"
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "langgraph_branch_tasks",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
